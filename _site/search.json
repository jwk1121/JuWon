[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "JuWon Kwon",
    "section": "",
    "text": "바이오메디컬공학을 전공하고 있는 학부생 입니다.\n초음파와 딥러닝을 공부하고 있습니다."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "JuWon Kwon",
    "section": "",
    "text": "바이오메디컬공학을 전공하고 있는 학부생 입니다.\n초음파와 딥러닝을 공부하고 있습니다."
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "test"
  },
  {
    "objectID": "rstat101.html",
    "href": "rstat101.html",
    "title": "Tutorial",
    "section": "",
    "text": "test12414입니\n123123다"
  },
  {
    "objectID": "tutorial_1.html",
    "href": "tutorial_1.html",
    "title": "test123",
    "section": "",
    "text": "안녕하세요 권주원입니다\nqmd test 진행중입니다"
  },
  {
    "objectID": "docs/rstat/rstat101.html",
    "href": "docs/rstat/rstat101.html",
    "title": "Tutorial",
    "section": "",
    "text": "test12414입니\n123123다"
  },
  {
    "objectID": "docs/rstat/rstat_lecture.html",
    "href": "docs/rstat/rstat_lecture.html",
    "title": "rstat lecture",
    "section": "",
    "text": "1강\n2강\n3강"
  },
  {
    "objectID": "docs/rstat/index.html",
    "href": "docs/rstat/index.html",
    "title": "Quarto blog",
    "section": "",
    "text": "CNN\n\n\nCNN part1 test\n\n\n\n\nDL\n\n\nCNN\n\n\n\n\n\n\n\n\n\n\n\nFeb 13, 2022\n\n\nJuWon\n\n\n\n\n\n\n  \n\n\n\n\nTutorial\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "docs/rstat/posts/rstat101.html",
    "href": "docs/rstat/posts/rstat101.html",
    "title": "Tutorial",
    "section": "",
    "text": "test12414입니\n123123다"
  },
  {
    "objectID": "docs/rstat/posts/rstat_lecture.html",
    "href": "docs/rstat/posts/rstat_lecture.html",
    "title": "rstat lecture",
    "section": "",
    "text": "1강\n2강\n3강"
  },
  {
    "objectID": "docs/rstat/posts/DL_CNN.html",
    "href": "docs/rstat/posts/DL_CNN.html",
    "title": "CNN",
    "section": "",
    "text": "toc:true\n\n\nimport torch \nimport torchvision\nfrom fastai.vision.all import * \nimport time\n\n\n\n간략하게 CNN의 구조를 설명하자면 - conv layer: 커널층(선형변환처럼 feature를 늘려주는 역할) - ReLU layer: 비선형을 추가해 표현력을 늘려주는 역할 - pooling layer: max 또는 avg를 통해 데이터를 요약해주는 역할\n\n\n\ntorch.manual_seed(43052)\n_conv = torch.nn.Conv2d(1,1,(2,2)) # 입력1, 출력1, (2,2) window size\n# (굳이 (2,2) 이런식으로 안해도 됨 어차피 윈도우 사이즈는 정사각행렬이므로 상수하나만 입력해도 됨됨)\n\n_X = torch.arange(0,25).float().reshape(1,5,5)\n_X\n\ntensor([[[ 0.,  1.,  2.,  3.,  4.],\n         [ 5.,  6.,  7.,  8.,  9.],\n         [10., 11., 12., 13., 14.],\n         [15., 16., 17., 18., 19.],\n         [20., 21., 22., 23., 24.]]])\n\n\n\n_conv.weight.data = torch.tensor([[[[0.25, 0.25],[0.25,0.25]]]])\n_conv.bias.data = torch.tensor([0.0])\n_conv.weight.data, _conv.bias.data\n\n(tensor([[[[0.2500, 0.2500],\n           [0.2500, 0.2500]]]]), tensor([0.]))\n\n\n\n_conv(_X)\n\ntensor([[[ 3.,  4.,  5.,  6.],\n         [ 8.,  9., 10., 11.],\n         [13., 14., 15., 16.],\n         [18., 19., 20., 21.]]], grad_fn=&lt;SqueezeBackward1&gt;)\n\n\nconv_tensor[1,1] = [[0, 1],[5, 6]]의 평균임을 알 수 있음 (conv.weight가 모두 1/4이어서 그런거임) - 해당 값은 (0 + 1 + 5 + 6) / 4 임을 알 수 있음 - 윈도우(커널)는 한 칸씩 움직이면서 weight를 곱하고 bias를 더함 - 첫 번째 3이라는 값은 [[0, 1],[5, 6]]에 conv을 적용 - 두 번째 4라는 값은 [[1, 2],[6, 7]]에 conv을 적용\n\n\n\n\n\n사실 ReLU는 DNN에서와 같이 음수는 0으로 양수는 그대로 되는 함수이다.\n\\(ReLU(x) = \\max(0,x)\\)\n\n\n\n\n\npooling layer에는 maxpooling이 있고 avgpooling이 있지만 이번에는 maxpooling을 다룰것임\nmaxpooling은 데이터 요약보다는 크기를 줄이는 느낌이 있음\n\n\n_maxpooling = torch.nn.MaxPool2d((2,2))\n_X = torch.arange(0,25).float().reshape(1,5,5)\n_X\n\ntensor([[[ 0.,  1.,  2.,  3.,  4.],\n         [ 5.,  6.,  7.,  8.,  9.],\n         [10., 11., 12., 13., 14.],\n         [15., 16., 17., 18., 19.],\n         [20., 21., 22., 23., 24.]]])\n\n\n\n_maxpooling(_X) \n\ntensor([[[ 6.,  8.],\n         [16., 18.]]])\n\n\n\nmaxpooling_tensor[1,1] = [[0, 1],[5, 6]] 중 가장 큰 값을 이므로 5이다.\npooling은 convlayer와 달리 pooling box가 겹치지 않게 움직임\n\n이러한 특성으로 인해 5번째 열과 행에 있는 값들은 pooling box에 들어가지 못해 버려지게 된다\n\n\n\n\n\n\n\npath = untar_data(URLs.MNIST)\n\n\n\n\n\n\n    \n      \n      100.03% [15687680/15683414 00:02&lt;00:00]\n    \n    \n\n\n\n\n\n(path/'원하는 경로').ls()\n\n\n\ntorchvision.io.read_image()\n해당 함수에 데이터 이름(이미지 이름)을 넣어주면 이미지를 tensor형태로 출력\n\n# train data\nx0 = torch.stack([torchvision.io.read_image(str(fnames)) for fnames in (path/'training/0').ls()])\nx1 = torch.stack([torchvision.io.read_image(str(fnames)) for fnames in (path/'training/1').ls()])\nx_tr = torch.concat([x0, x1])/255\n\ny_tr = torch.tensor([0.0]*len(x0) + [1.0]*len(x1)).reshape(-1,1)\n\n\n# train data\nx0 = torch.stack([torchvision.io.read_image(str(fnames)) for fnames in (path/'testing/0').ls()])\nx1 = torch.stack([torchvision.io.read_image(str(fnames)) for fnames in (path/'testing/1').ls()])\nx_test = torch.concat([x0, x1])/255\n\ny_test = torch.tensor([0.0]*len(x0) + [1.0]*len(x1)).reshape(-1,1)\n\n\nx_tr.shape, y_tr.shape, x_test.shape, y_test.shape\n\n(torch.Size([12665, 1, 28, 28]),\n torch.Size([12665, 1]),\n torch.Size([2115, 1, 28, 28]),\n torch.Size([2115, 1]))\n\n\n\n\n\n# conv\nc1 = torch.nn.Conv2d(1, 16 , 5) # 만약 color image였다면 입력 채널의 수를 3으로 지정해야 함\nx_tr.shape ,c1(x_tr).shape\n\n(torch.Size([12665, 1, 28, 28]), torch.Size([12665, 16, 24, 24]))\n\n\n\nsize계산 공식: 윈도우(커널)사이즈가 n이면 \\(size = height(width) - ( n - 1)\\)\n\n\n# ReLU\na1 = torch.nn.ReLU()\n\n\n# maxpooling\nm1 = torch.nn.MaxPool2d(2)\nprint(m1(a1(c1(x_tr))).shape)\n\ntorch.Size([12665, 16, 12, 12])\n\n\n\n행과 열이 2의 배수이므로 maxpool이 2일때는 버려지는 행과 열은 없다.\n\n\n# flatten(이미지를 한줄로 펼치는 것)\nf1 = torch.nn.Flatten()\nprint(f1(a1(m1(c1(x_tr)))).shape) #16 * 12 * 12 = 2304\n\ntorch.Size([12665, 2304])\n\n\n\n# sigmoid에 올리기 위해서는 2304 디멘젼을 1로 만들어야함\nl1=torch.nn.Linear(in_features=2304,out_features=1) \n\n\n# sigmoid (값이 0에서 1사이의 값, 즉 확률로 출력되도록)\na2 = torch.nn.Sigmoid()\nprint(a2(f1(a1(m1(c1(x_tr))))).shape)\n\ntorch.Size([12665, 2304])\n\n\n\nprint('이미지 사이즈:                     ', x_tr.shape)\nprint('conv:                              ',c1(x_tr).shape)\nprint('(ReLU) -&gt; maxpooling:              ',m1(a1(c1(x_tr))).shape)\nprint('이미지 펼치기:                     ',f1(a1(m1(c1(x_tr)))).shape)\nprint('이미지를 하나의 스칼라로 선형변환: ',l1(f1(a1(m1(c1(x_tr))))).shape)\nprint('시그모이드:                        ',a2(l1(f1(a1(m1(c1(x_tr)))))).shape)\n\n이미지 사이즈:                      torch.Size([12665, 1, 28, 28])\nconv:                               torch.Size([12665, 16, 24, 24])\n(ReLU) -&gt; maxpooling:               torch.Size([12665, 16, 12, 12])\n이미지 펼치기:                      torch.Size([12665, 2304])\n이미지를 하나의 스칼라로 선형변환:  torch.Size([12665, 1])\n시그모이드:                         torch.Size([12665, 1])\n\n\n\n\n\n\n원래라면 아래와 같은 코드를 사용하여 network를 학습시키겠지만 CNN과 같이 파라미터가 많은 network는 CPU로 연산시 학습할때 시간이 오래걸림\n\nloss_fn=torch.nn.BCELoss()\noptimizr= torch.optim.Adam(net.parameters())\nt1= time.time()\nfor epoc in range(100): \n    ## 1 \n    yhat=net(x_tr)\n    ## 2 \n    loss=loss_fn(yhat,y_tr) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\\(\\to\\) overview때 배운 fastai에 있는 데이터로더를 사용하면 GPU를 사용해 연산을 할 수 있다.\n\n# 데이터 로더에 들어갈 데이터세트 준비\nds_tr = torch.utils.data.TensorDataset(x_tr, y_tr)\nds_test = torch.utils.data.TensorDataset(x_test, y_test)\n\n\n데이터 로더는 배치크기를 지정해줘야 함\n\n\nlen(x_tr), len(x_test)\n\n(12665, 2115)\n\n\n\n데이터가 각각 12665, 2115개씩 들어가 있으므로 한번 업데이트할 때 총 데이터의 1 /10을 쓰도록 아래와 같이 배치 크기를 줌\n\nstochastic gradient descent(구용어: mini-batch gradient descent)\n\n\n\n# 데이터 로더\ndl_tr = torch.utils.data.DataLoader(ds_tr,batch_size=1266) \ndl_test = torch.utils.data.DataLoader(ds_test,batch_size=2115) \n\n\ndls = DataLoaders(dl_tr,dl_test)\n\n\nnet = torch.nn.Sequential(\n    # conv layer \n    c1, \n    # ReLU\n    a1, \n    # maxpool\n    m1, \n    # flatten\n    f1, \n    # linear transform (n -&gt; 1)\n    l1,\n    # Sigmoid\n    a2\n)\n\nloss_fn=torch.nn.BCELoss()\n\n\nlrnr = Learner(dls,net,loss_fn) # fastai의 Learner는 오미타이저의 기본값이 adam이므로 따로 지정해주지 않아도 됨\n\n\nlrnr.fit(10)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n0.979273\n0.639250\n00:05\n\n\n1\n0.703008\n0.402466\n00:00\n\n\n2\n0.547401\n0.256881\n00:00\n\n\n3\n0.434025\n0.142217\n00:00\n\n\n4\n0.340996\n0.079636\n00:00\n\n\n5\n0.267902\n0.048050\n00:00\n\n\n6\n0.211895\n0.031742\n00:00\n\n\n7\n0.169176\n0.022921\n00:00\n\n\n8\n0.136331\n0.017658\n00:00\n\n\n9\n0.110770\n0.014233\n00:00\n\n\n\n\n\n\nLearner 오브젝트에 들어간 net은 gpu상에 있도록 되어있음 &gt; python    net[0].weight 위 코드를 출력하면 weight tensor가 출력되는데 가장 밑을 확인하면 device = ’cuda:0’라는 것이 있음. 이는 해당 tensor가 gpu상에 위치해있는 것을 의미한다.\n+ tensor 연산을 할 때에는 모든 tensor가 같은 곳에 위치해있어야 한다.\n\n\nnet = net.to('cpu')\nplt.plot(net(x_tr).data,'.')\nplt.title(\"Training Set\",size=15)\n\nText(0.5, 1.0, 'Training Set')\n\n\n\n\n\n\nplt.plot(net(x_test).data,'.')\nplt.title(\"Testing Set\",size=15)\n\nText(0.5, 1.0, 'Testing Set')\n\n\n\n\n\n\n\n\n\n\n\n\nBCEWithLogitsLoss = Sigmoid + BCELoss\n손실함수로 이를 사용하면 network 마지막에 시그모이드 함수를 추가하지 않아도 됨\n이를 사용하면 수치적으로 더 안정이 된다는 장점이 있음\n\n\n\n\n\n\n다중(k개) 클래스를 분류 - LossFunction: CrossEntrophyLoss\n- ActivationFunction: SoftmaxFunction - 마지막 출력층: torch.nn.Linear(n, k)\n\n\n\n\n소프트맥스 함수가 계산하는 과정은 아래와 같음 (3개를 분류할 경우) \\(softmax=\\frac{e^{a 또는 b 또는 c}}{e^{a} + e^{b} + e^{c}}\\)\n\n\n\n\n\nk개의 클래스를 분류하는 모델의 Loss 계산 방법\n\nsftmax(_netout) # -&gt; 0 ~ 1 사이의 값 k개 출력\n\ntorch.log(sftmax(_netout)) # -&gt; 0 ~ 1사이의 값을 로그에 넣게 되면 -∞ ~ 0사이의 값 k개 출력\n\n- torch.log(sftmax(_netout)) * _y_onehot \n# 만약 값이 log(sftmax(_netout)) = [-2.2395, -2.2395, -0.2395] 이렇게 나오고 \n#y_onehot이 [1, 0, 0]이라면 해당 코드의 결과, 즉 loss는 2.2395이 된다. \n\n만약 모델이 첫 번째 값이 확실하게 정답이라고 생각한다면 로그의 결과값은 0이 된다 -&gt; 해당 값이 정답일경우 0 * 1 = 0이므로 loss는 0이 된다\n최종적으로는 위 코드를 통해 얻은 Loss를 평균을 내어 출력한다.\n\n+ 위의 설명은 정답이 원-핫 인코딩 형식으로 되어있을 때의 Loss계산 방법임\n+ 정답이 vector + 정수형으로 되어 있을 때의 Loss계산 방법은 잘 모르겠음\n\n\n\n\ntype 1) int형을 사용하는 방법 (vector)\ntype 2) float형을 사용하는 방법 (one-hot encoded vector)\n만약 사슴, 강아지, 고양이를 분류하는 모델이라면\n\ntype 1)의 경우 &lt;사슴: 0, 강아지: 1, 고양이: 2&gt; (단, 데이터 형태는는 int(정수))\ntype 2)의 경우 &lt;사슴: [1, 0, 0], 강아지: [0, 1, 0], 고양이: [0, 0, 1] &gt; (단, 데이터의 형태는 float(실수))\n\n\n\n\n\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\n\n\ntorch.tensor([0]*len(X0) + [1]*len(X1))#.reshape(-1,1)\n\ntensor([0, 0, 0,  ..., 1, 1, 1])\n\n\n\n\n\n\nyy = torch.tensor([0]*len(X0) + [1]*len(X1))#.reshape(-1,1)\ntorch.nn.functional.one_hot(yy).float()\n\ntensor([[1., 0.],\n        [1., 0.],\n        [1., 0.],\n        ...,\n        [0., 1.],\n        [0., 1.],\n        [0., 1.]])\n\n\n\n\n\n\n\n# train\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\nX2 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/2').ls()])\nX = torch.concat([X0,X1,X2])/255\ny = torch.tensor([0]*len(X0) + [1]*len(X1)+ [2]*len(X2))#.reshape(-1,1)\n\n\n# test\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'testing/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'testing/1').ls()])\nX2 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'testing/2').ls()])\nXX = torch.concat([X0,X1,X2])/255\nyy = torch.tensor([0]*len(X0) + [1]*len(X1)+ [2]*len(X2))#.reshape(-1,1)\n\n\nlen(X) # 18623\n\n18623\n\n\n\nds1 = torch.utils.data.TensorDataset(X,y) \nds2 = torch.utils.data.TensorDataset(XX,yy) \ndl1 = torch.utils.data.DataLoader(ds1,batch_size=1862) # 에폭당 11번= 1862 꽉 채워서 10번하고 3개정도 남은 걸로 한 번\ndl2 = torch.utils.data.DataLoader(ds2,batch_size=3147) # test는 전부다 넣어서\ndls = DataLoaders(dl1,dl2) \n\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten(),\n    torch.nn.Linear(2304,3) # 0,1,2 3개를 구분하는 문제이므로 out_features=3 \n)\n\nloss_fn = torch.nn.CrossEntropyLoss() # 여기에는 softmax함수가 내장되어 있음 \n#-&gt; net마지막에 softmax를 넣으면 안됨\n# BCEWithLogitsLoss 느낌(시그모이드 + BCE)\n\n\nlrnr = Learner(dls,net,loss_fn) # 옵티마이저는 아답이 디폴트 값이어서 굳이 안넣어도 됨\n\n\nlrnr.fit(10) \n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n1.797101\n1.103916\n00:00\n\n\n1\n1.267011\n0.823797\n00:00\n\n\n2\n1.055513\n0.667210\n00:00\n\n\n3\n0.910746\n0.435414\n00:00\n\n\n4\n0.762887\n0.284001\n00:00\n\n\n5\n0.625515\n0.199502\n00:00\n\n\n6\n0.515352\n0.152906\n00:00\n\n\n7\n0.429145\n0.123678\n00:00\n\n\n8\n0.359694\n0.105466\n00:00\n\n\n9\n0.303888\n0.092883\n00:00\n\n\n\n\n\n\nlrnr.model.to(\"cpu\")\n\npd.DataFrame(lrnr.model(XX)).assign(y=yy) \n\n\n  \n    \n      \n\n\n\n\n\n\n0\n1\n2\ny\n\n\n\n\n0\n0.981043\n-9.135092\n-1.149270\n0\n\n\n1\n-0.292905\n-4.281692\n-0.924575\n0\n\n\n2\n4.085316\n-9.199694\n-3.482234\n0\n\n\n3\n2.484926\n-9.336347\n-3.127304\n0\n\n\n4\n3.310040\n-12.257785\n-2.177761\n0\n\n\n...\n...\n...\n...\n...\n\n\n3142\n-1.138366\n-5.435792\n0.370670\n2\n\n\n3143\n-4.458741\n-4.281343\n2.052410\n2\n\n\n3144\n-2.836508\n-3.204013\n0.012610\n2\n\n\n3145\n-1.704158\n-10.621873\n2.024313\n2\n\n\n3146\n-2.467648\n-4.612999\n0.656284\n2\n\n\n\n\n\n3147 rows × 4 columns\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\npd.DataFrame(lrnr.model(XX)).assign(y=yy).query('y==0')\n\n\n  \n    \n      \n\n\n\n\n\n\n0\n1\n2\ny\n\n\n\n\n0\n0.981043\n-9.135092\n-1.149270\n0\n\n\n1\n-0.292905\n-4.281692\n-0.924575\n0\n\n\n2\n4.085316\n-9.199694\n-3.482234\n0\n\n\n3\n2.484926\n-9.336347\n-3.127304\n0\n\n\n4\n3.310040\n-12.257785\n-2.177761\n0\n\n\n...\n...\n...\n...\n...\n\n\n975\n0.432969\n-5.653580\n-1.944451\n0\n\n\n976\n2.685695\n-10.254354\n-2.466680\n0\n\n\n977\n2.474842\n-9.650204\n-2.452746\n0\n\n\n978\n1.268743\n-6.928779\n-1.419695\n0\n\n\n979\n4.371464\n-8.959077\n-4.056257\n0\n\n\n\n\n\n980 rows × 4 columns\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\n0으로 분류한 것들은 첫번째 열(0)의 값이 가장 큼\n\n\n\n\n\n이진 분류시에는 소프트맥스와 시그모이드 모두 activation function으로 사용할 수 있지만 소프트맥스를 사용하면 출력층이 2개가 되므로 파라미터 낭비가 심해진다.\n이진 분류시에는 시그모이드를 사용하는 것이 적합함.\n소프트맥스는 3개 이상을 분류해야 할 경우에 사용하면 됨\n\n\n\n\n\nfastai에서 지원\nfastai를 사용해 학습(lrnr.fit())을 할때 loss_value만 나오는 것이 아니라 error_rate과 정확도가 나오게 할 수 있는 옵션\ny의 형태를 주의해서 사용해야 함\n\n앞서 말한 것처럼 두 가지 타입이 있음\n\nvector + int\none-hot encoded vector + float\n\n\n\ntype 1) y의 형태가 vector + int일 때 - metrics = accuracy를 사용해야 함\n\n# train\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\nX = torch.concat([X0,X1])/255\n\n\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\ny.to(torch.int64).reshape(-1)\n\ntensor([0, 0, 0,  ..., 1, 1, 1])\n\n\n\n# test\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'testing/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'testing/1').ls()])\nXX = torch.concat([X0,X1])/255\n\n\nyy = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\nyy.to(torch.int64).reshape(-1)\n\ntensor([0, 0, 0,  ..., 1, 1, 1])\n\n\n\nds1 = torch.utils.data.TensorDataset(X,y.to(torch.int64).reshape(-1))\nds2 = torch.utils.data.TensorDataset(XX,yy.to(torch.int64).reshape(-1))\n\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=1266) \ndl2 = torch.utils.data.DataLoader(ds2,batch_size=2115) \n\ndls = DataLoaders(dl1,dl2) \n\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten(),\n    torch.nn.Linear(2304,2)\n)\nloss_fn = torch.nn.CrossEntropyLoss() \nlrnr = Learner(dls,net,loss_fn,metrics=[accuracy,error_rate])\n\n\nlrnr.fit(10)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\nerror_rate\ntime\n\n\n\n\n0\n1.128365\n0.601474\n0.463357\n0.536643\n00:00\n\n\n1\n0.684630\n0.304262\n0.975414\n0.024586\n00:00\n\n\n2\n0.503124\n0.144147\n0.989598\n0.010402\n00:00\n\n\n3\n0.373899\n0.068306\n0.996217\n0.003783\n00:00\n\n\n4\n0.281332\n0.040790\n0.996217\n0.003783\n00:00\n\n\n5\n0.215743\n0.026980\n0.996690\n0.003310\n00:00\n\n\n6\n0.168349\n0.019467\n0.996690\n0.003310\n00:00\n\n\n7\n0.133313\n0.014856\n0.998109\n0.001891\n00:00\n\n\n8\n0.106776\n0.011745\n0.998109\n0.001891\n00:00\n\n\n9\n0.086275\n0.009553\n0.999054\n0.000946\n00:00\n\n\n\n\n\ntype 2) y의 형태가 one-hot encoded vector + float일 때 - metrics = accuracy_multi를 사용해야 함 - error_rate는 사용못함\n\ny_onehot = torch.tensor(list(map(lambda x: [1.0,0.0] if x==0 else [0.0,1.0], y)))\nyy_onehot = torch.tensor(list(map(lambda x: [1.0,0.0] if x==0 else [0.0,1.0], yy)))\n\n\ny_onehot = torch.nn.functional.one_hot(y.reshape(-1).to(torch.int64)).to(torch.float32)\nyy_onehot = torch.nn.functional.one_hot(yy.reshape(-1).to(torch.int64)).to(torch.float32)\n\n\ntorch.nn.functional.one_hot() 함수 조건\n\n기본적으로 크기가 n인 벡터가 들어오길 기대\n정수가 들어오는 것을 기대\n\n하지만 원-핫 인코딩을 사용할 때에는 실수형으로 저장 되어야 하므로 마지막에 실수형으로 바꿔줘야 함\n\n\nds1 = torch.utils.data.TensorDataset(X,y_onehot)\nds2 = torch.utils.data.TensorDataset(XX,yy_onehot)\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=1266) \ndl2 = torch.utils.data.DataLoader(ds2,batch_size=2115) \ndls = DataLoaders(dl1,dl2) \n\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten(),\n    torch.nn.Linear(2304,2),\n    #torch.nn.Softmax()\n)\nloss_fn = torch.nn.CrossEntropyLoss() \nlrnr = Learner(dls,net,loss_fn,metrics=[accuracy_multi])\n\n\nlrnr.fit(10)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy_multi\ntime\n\n\n\n\n0\n1.213650\n0.647844\n0.463357\n00:00\n\n\n1\n0.744869\n0.384000\n0.933570\n00:00\n\n\n2\n0.571879\n0.187119\n0.986525\n00:00\n\n\n3\n0.432096\n0.090841\n0.994563\n00:00\n\n\n4\n0.326718\n0.048868\n0.995508\n00:00\n\n\n5\n0.250235\n0.028477\n0.996217\n00:00\n\n\n6\n0.194605\n0.018616\n0.996454\n00:00\n\n\n7\n0.153338\n0.013278\n0.996927\n00:00\n\n\n8\n0.122056\n0.010130\n0.997872\n00:00\n\n\n9\n0.097957\n0.008112\n0.998109\n00:00"
  },
  {
    "objectID": "docs/rstat/posts/DL_CNN.html#cnn-구조",
    "href": "docs/rstat/posts/DL_CNN.html#cnn-구조",
    "title": "CNN",
    "section": "",
    "text": "간략하게 CNN의 구조를 설명하자면 - conv layer: 커널층(선형변환처럼 feature를 늘려주는 역할) - ReLU layer: 비선형을 추가해 표현력을 늘려주는 역할 - pooling layer: max 또는 avg를 통해 데이터를 요약해주는 역할\n\n\n\ntorch.manual_seed(43052)\n_conv = torch.nn.Conv2d(1,1,(2,2)) # 입력1, 출력1, (2,2) window size\n# (굳이 (2,2) 이런식으로 안해도 됨 어차피 윈도우 사이즈는 정사각행렬이므로 상수하나만 입력해도 됨됨)\n\n_X = torch.arange(0,25).float().reshape(1,5,5)\n_X\n\ntensor([[[ 0.,  1.,  2.,  3.,  4.],\n         [ 5.,  6.,  7.,  8.,  9.],\n         [10., 11., 12., 13., 14.],\n         [15., 16., 17., 18., 19.],\n         [20., 21., 22., 23., 24.]]])\n\n\n\n_conv.weight.data = torch.tensor([[[[0.25, 0.25],[0.25,0.25]]]])\n_conv.bias.data = torch.tensor([0.0])\n_conv.weight.data, _conv.bias.data\n\n(tensor([[[[0.2500, 0.2500],\n           [0.2500, 0.2500]]]]), tensor([0.]))\n\n\n\n_conv(_X)\n\ntensor([[[ 3.,  4.,  5.,  6.],\n         [ 8.,  9., 10., 11.],\n         [13., 14., 15., 16.],\n         [18., 19., 20., 21.]]], grad_fn=&lt;SqueezeBackward1&gt;)\n\n\nconv_tensor[1,1] = [[0, 1],[5, 6]]의 평균임을 알 수 있음 (conv.weight가 모두 1/4이어서 그런거임) - 해당 값은 (0 + 1 + 5 + 6) / 4 임을 알 수 있음 - 윈도우(커널)는 한 칸씩 움직이면서 weight를 곱하고 bias를 더함 - 첫 번째 3이라는 값은 [[0, 1],[5, 6]]에 conv을 적용 - 두 번째 4라는 값은 [[1, 2],[6, 7]]에 conv을 적용\n\n\n\n\n\n사실 ReLU는 DNN에서와 같이 음수는 0으로 양수는 그대로 되는 함수이다.\n\\(ReLU(x) = \\max(0,x)\\)\n\n\n\n\n\npooling layer에는 maxpooling이 있고 avgpooling이 있지만 이번에는 maxpooling을 다룰것임\nmaxpooling은 데이터 요약보다는 크기를 줄이는 느낌이 있음\n\n\n_maxpooling = torch.nn.MaxPool2d((2,2))\n_X = torch.arange(0,25).float().reshape(1,5,5)\n_X\n\ntensor([[[ 0.,  1.,  2.,  3.,  4.],\n         [ 5.,  6.,  7.,  8.,  9.],\n         [10., 11., 12., 13., 14.],\n         [15., 16., 17., 18., 19.],\n         [20., 21., 22., 23., 24.]]])\n\n\n\n_maxpooling(_X) \n\ntensor([[[ 6.,  8.],\n         [16., 18.]]])\n\n\n\nmaxpooling_tensor[1,1] = [[0, 1],[5, 6]] 중 가장 큰 값을 이므로 5이다.\npooling은 convlayer와 달리 pooling box가 겹치지 않게 움직임\n\n이러한 특성으로 인해 5번째 열과 행에 있는 값들은 pooling box에 들어가지 못해 버려지게 된다"
  },
  {
    "objectID": "docs/rstat/posts/DL_CNN.html#cnn-구현",
    "href": "docs/rstat/posts/DL_CNN.html#cnn-구현",
    "title": "CNN",
    "section": "",
    "text": "path = untar_data(URLs.MNIST)\n\n\n\n\n\n\n    \n      \n      100.03% [15687680/15683414 00:02&lt;00:00]"
  },
  {
    "objectID": "docs/rstat/posts/DL_CNN.html#path-사용법-데이터-준비",
    "href": "docs/rstat/posts/DL_CNN.html#path-사용법-데이터-준비",
    "title": "CNN",
    "section": "",
    "text": "(path/'원하는 경로').ls()"
  },
  {
    "objectID": "docs/rstat/posts/DL_CNN.html#위-코드를-사용하면-폴더-안에-있는-데이터들의-이름을-출력",
    "href": "docs/rstat/posts/DL_CNN.html#위-코드를-사용하면-폴더-안에-있는-데이터들의-이름을-출력",
    "title": "CNN",
    "section": "",
    "text": "torchvision.io.read_image()\n해당 함수에 데이터 이름(이미지 이름)을 넣어주면 이미지를 tensor형태로 출력\n\n# train data\nx0 = torch.stack([torchvision.io.read_image(str(fnames)) for fnames in (path/'training/0').ls()])\nx1 = torch.stack([torchvision.io.read_image(str(fnames)) for fnames in (path/'training/1').ls()])\nx_tr = torch.concat([x0, x1])/255\n\ny_tr = torch.tensor([0.0]*len(x0) + [1.0]*len(x1)).reshape(-1,1)\n\n\n# train data\nx0 = torch.stack([torchvision.io.read_image(str(fnames)) for fnames in (path/'testing/0').ls()])\nx1 = torch.stack([torchvision.io.read_image(str(fnames)) for fnames in (path/'testing/1').ls()])\nx_test = torch.concat([x0, x1])/255\n\ny_test = torch.tensor([0.0]*len(x0) + [1.0]*len(x1)).reshape(-1,1)\n\n\nx_tr.shape, y_tr.shape, x_test.shape, y_test.shape\n\n(torch.Size([12665, 1, 28, 28]),\n torch.Size([12665, 1]),\n torch.Size([2115, 1, 28, 28]),\n torch.Size([2115, 1]))\n\n\n\n\n\n# conv\nc1 = torch.nn.Conv2d(1, 16 , 5) # 만약 color image였다면 입력 채널의 수를 3으로 지정해야 함\nx_tr.shape ,c1(x_tr).shape\n\n(torch.Size([12665, 1, 28, 28]), torch.Size([12665, 16, 24, 24]))\n\n\n\nsize계산 공식: 윈도우(커널)사이즈가 n이면 \\(size = height(width) - ( n - 1)\\)\n\n\n# ReLU\na1 = torch.nn.ReLU()\n\n\n# maxpooling\nm1 = torch.nn.MaxPool2d(2)\nprint(m1(a1(c1(x_tr))).shape)\n\ntorch.Size([12665, 16, 12, 12])\n\n\n\n행과 열이 2의 배수이므로 maxpool이 2일때는 버려지는 행과 열은 없다.\n\n\n# flatten(이미지를 한줄로 펼치는 것)\nf1 = torch.nn.Flatten()\nprint(f1(a1(m1(c1(x_tr)))).shape) #16 * 12 * 12 = 2304\n\ntorch.Size([12665, 2304])\n\n\n\n# sigmoid에 올리기 위해서는 2304 디멘젼을 1로 만들어야함\nl1=torch.nn.Linear(in_features=2304,out_features=1) \n\n\n# sigmoid (값이 0에서 1사이의 값, 즉 확률로 출력되도록)\na2 = torch.nn.Sigmoid()\nprint(a2(f1(a1(m1(c1(x_tr))))).shape)\n\ntorch.Size([12665, 2304])\n\n\n\nprint('이미지 사이즈:                     ', x_tr.shape)\nprint('conv:                              ',c1(x_tr).shape)\nprint('(ReLU) -&gt; maxpooling:              ',m1(a1(c1(x_tr))).shape)\nprint('이미지 펼치기:                     ',f1(a1(m1(c1(x_tr)))).shape)\nprint('이미지를 하나의 스칼라로 선형변환: ',l1(f1(a1(m1(c1(x_tr))))).shape)\nprint('시그모이드:                        ',a2(l1(f1(a1(m1(c1(x_tr)))))).shape)\n\n이미지 사이즈:                      torch.Size([12665, 1, 28, 28])\nconv:                               torch.Size([12665, 16, 24, 24])\n(ReLU) -&gt; maxpooling:               torch.Size([12665, 16, 12, 12])\n이미지 펼치기:                      torch.Size([12665, 2304])\n이미지를 하나의 스칼라로 선형변환:  torch.Size([12665, 1])\n시그모이드:                         torch.Size([12665, 1])\n\n\n\n\n\n\n원래라면 아래와 같은 코드를 사용하여 network를 학습시키겠지만 CNN과 같이 파라미터가 많은 network는 CPU로 연산시 학습할때 시간이 오래걸림\n\nloss_fn=torch.nn.BCELoss()\noptimizr= torch.optim.Adam(net.parameters())\nt1= time.time()\nfor epoc in range(100): \n    ## 1 \n    yhat=net(x_tr)\n    ## 2 \n    loss=loss_fn(yhat,y_tr) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\\(\\to\\) overview때 배운 fastai에 있는 데이터로더를 사용하면 GPU를 사용해 연산을 할 수 있다.\n\n# 데이터 로더에 들어갈 데이터세트 준비\nds_tr = torch.utils.data.TensorDataset(x_tr, y_tr)\nds_test = torch.utils.data.TensorDataset(x_test, y_test)\n\n\n데이터 로더는 배치크기를 지정해줘야 함\n\n\nlen(x_tr), len(x_test)\n\n(12665, 2115)\n\n\n\n데이터가 각각 12665, 2115개씩 들어가 있으므로 한번 업데이트할 때 총 데이터의 1 /10을 쓰도록 아래와 같이 배치 크기를 줌\n\nstochastic gradient descent(구용어: mini-batch gradient descent)\n\n\n\n# 데이터 로더\ndl_tr = torch.utils.data.DataLoader(ds_tr,batch_size=1266) \ndl_test = torch.utils.data.DataLoader(ds_test,batch_size=2115) \n\n\ndls = DataLoaders(dl_tr,dl_test)\n\n\nnet = torch.nn.Sequential(\n    # conv layer \n    c1, \n    # ReLU\n    a1, \n    # maxpool\n    m1, \n    # flatten\n    f1, \n    # linear transform (n -&gt; 1)\n    l1,\n    # Sigmoid\n    a2\n)\n\nloss_fn=torch.nn.BCELoss()\n\n\nlrnr = Learner(dls,net,loss_fn) # fastai의 Learner는 오미타이저의 기본값이 adam이므로 따로 지정해주지 않아도 됨\n\n\nlrnr.fit(10)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n0.979273\n0.639250\n00:05\n\n\n1\n0.703008\n0.402466\n00:00\n\n\n2\n0.547401\n0.256881\n00:00\n\n\n3\n0.434025\n0.142217\n00:00\n\n\n4\n0.340996\n0.079636\n00:00\n\n\n5\n0.267902\n0.048050\n00:00\n\n\n6\n0.211895\n0.031742\n00:00\n\n\n7\n0.169176\n0.022921\n00:00\n\n\n8\n0.136331\n0.017658\n00:00\n\n\n9\n0.110770\n0.014233\n00:00\n\n\n\n\n\n\nLearner 오브젝트에 들어간 net은 gpu상에 있도록 되어있음 &gt; python    net[0].weight 위 코드를 출력하면 weight tensor가 출력되는데 가장 밑을 확인하면 device = ’cuda:0’라는 것이 있음. 이는 해당 tensor가 gpu상에 위치해있는 것을 의미한다.\n+ tensor 연산을 할 때에는 모든 tensor가 같은 곳에 위치해있어야 한다.\n\n\nnet = net.to('cpu')\nplt.plot(net(x_tr).data,'.')\nplt.title(\"Training Set\",size=15)\n\nText(0.5, 1.0, 'Training Set')\n\n\n\n\n\n\nplt.plot(net(x_test).data,'.')\nplt.title(\"Testing Set\",size=15)\n\nText(0.5, 1.0, 'Testing Set')"
  },
  {
    "objectID": "docs/rstat/posts/DL_CNN.html#loss-function",
    "href": "docs/rstat/posts/DL_CNN.html#loss-function",
    "title": "CNN",
    "section": "",
    "text": "BCEWithLogitsLoss = Sigmoid + BCELoss\n손실함수로 이를 사용하면 network 마지막에 시그모이드 함수를 추가하지 않아도 됨\n이를 사용하면 수치적으로 더 안정이 된다는 장점이 있음"
  },
  {
    "objectID": "docs/rstat/posts/DL_CNN.html#k개의-클래스를-분류하는-모델",
    "href": "docs/rstat/posts/DL_CNN.html#k개의-클래스를-분류하는-모델",
    "title": "CNN",
    "section": "",
    "text": "다중(k개) 클래스를 분류 - LossFunction: CrossEntrophyLoss\n- ActivationFunction: SoftmaxFunction - 마지막 출력층: torch.nn.Linear(n, k)\n\n\n\n\n소프트맥스 함수가 계산하는 과정은 아래와 같음 (3개를 분류할 경우) \\(softmax=\\frac{e^{a 또는 b 또는 c}}{e^{a} + e^{b} + e^{c}}\\)\n\n\n\n\n\nk개의 클래스를 분류하는 모델의 Loss 계산 방법\n\nsftmax(_netout) # -&gt; 0 ~ 1 사이의 값 k개 출력\n\ntorch.log(sftmax(_netout)) # -&gt; 0 ~ 1사이의 값을 로그에 넣게 되면 -∞ ~ 0사이의 값 k개 출력\n\n- torch.log(sftmax(_netout)) * _y_onehot \n# 만약 값이 log(sftmax(_netout)) = [-2.2395, -2.2395, -0.2395] 이렇게 나오고 \n#y_onehot이 [1, 0, 0]이라면 해당 코드의 결과, 즉 loss는 2.2395이 된다. \n\n만약 모델이 첫 번째 값이 확실하게 정답이라고 생각한다면 로그의 결과값은 0이 된다 -&gt; 해당 값이 정답일경우 0 * 1 = 0이므로 loss는 0이 된다\n최종적으로는 위 코드를 통해 얻은 Loss를 평균을 내어 출력한다.\n\n+ 위의 설명은 정답이 원-핫 인코딩 형식으로 되어있을 때의 Loss계산 방법임\n+ 정답이 vector + 정수형으로 되어 있을 때의 Loss계산 방법은 잘 모르겠음\n\n\n\n\ntype 1) int형을 사용하는 방법 (vector)\ntype 2) float형을 사용하는 방법 (one-hot encoded vector)\n만약 사슴, 강아지, 고양이를 분류하는 모델이라면\n\ntype 1)의 경우 &lt;사슴: 0, 강아지: 1, 고양이: 2&gt; (단, 데이터 형태는는 int(정수))\ntype 2)의 경우 &lt;사슴: [1, 0, 0], 강아지: [0, 1, 0], 고양이: [0, 0, 1] &gt; (단, 데이터의 형태는 float(실수))\n\n\n\n\n\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\n\n\ntorch.tensor([0]*len(X0) + [1]*len(X1))#.reshape(-1,1)\n\ntensor([0, 0, 0,  ..., 1, 1, 1])\n\n\n\n\n\n\nyy = torch.tensor([0]*len(X0) + [1]*len(X1))#.reshape(-1,1)\ntorch.nn.functional.one_hot(yy).float()\n\ntensor([[1., 0.],\n        [1., 0.],\n        [1., 0.],\n        ...,\n        [0., 1.],\n        [0., 1.],\n        [0., 1.]])\n\n\n\n\n\n\n\n# train\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\nX2 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/2').ls()])\nX = torch.concat([X0,X1,X2])/255\ny = torch.tensor([0]*len(X0) + [1]*len(X1)+ [2]*len(X2))#.reshape(-1,1)\n\n\n# test\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'testing/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'testing/1').ls()])\nX2 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'testing/2').ls()])\nXX = torch.concat([X0,X1,X2])/255\nyy = torch.tensor([0]*len(X0) + [1]*len(X1)+ [2]*len(X2))#.reshape(-1,1)\n\n\nlen(X) # 18623\n\n18623\n\n\n\nds1 = torch.utils.data.TensorDataset(X,y) \nds2 = torch.utils.data.TensorDataset(XX,yy) \ndl1 = torch.utils.data.DataLoader(ds1,batch_size=1862) # 에폭당 11번= 1862 꽉 채워서 10번하고 3개정도 남은 걸로 한 번\ndl2 = torch.utils.data.DataLoader(ds2,batch_size=3147) # test는 전부다 넣어서\ndls = DataLoaders(dl1,dl2) \n\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten(),\n    torch.nn.Linear(2304,3) # 0,1,2 3개를 구분하는 문제이므로 out_features=3 \n)\n\nloss_fn = torch.nn.CrossEntropyLoss() # 여기에는 softmax함수가 내장되어 있음 \n#-&gt; net마지막에 softmax를 넣으면 안됨\n# BCEWithLogitsLoss 느낌(시그모이드 + BCE)\n\n\nlrnr = Learner(dls,net,loss_fn) # 옵티마이저는 아답이 디폴트 값이어서 굳이 안넣어도 됨\n\n\nlrnr.fit(10) \n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n1.797101\n1.103916\n00:00\n\n\n1\n1.267011\n0.823797\n00:00\n\n\n2\n1.055513\n0.667210\n00:00\n\n\n3\n0.910746\n0.435414\n00:00\n\n\n4\n0.762887\n0.284001\n00:00\n\n\n5\n0.625515\n0.199502\n00:00\n\n\n6\n0.515352\n0.152906\n00:00\n\n\n7\n0.429145\n0.123678\n00:00\n\n\n8\n0.359694\n0.105466\n00:00\n\n\n9\n0.303888\n0.092883\n00:00\n\n\n\n\n\n\nlrnr.model.to(\"cpu\")\n\npd.DataFrame(lrnr.model(XX)).assign(y=yy) \n\n\n  \n    \n      \n\n\n\n\n\n\n0\n1\n2\ny\n\n\n\n\n0\n0.981043\n-9.135092\n-1.149270\n0\n\n\n1\n-0.292905\n-4.281692\n-0.924575\n0\n\n\n2\n4.085316\n-9.199694\n-3.482234\n0\n\n\n3\n2.484926\n-9.336347\n-3.127304\n0\n\n\n4\n3.310040\n-12.257785\n-2.177761\n0\n\n\n...\n...\n...\n...\n...\n\n\n3142\n-1.138366\n-5.435792\n0.370670\n2\n\n\n3143\n-4.458741\n-4.281343\n2.052410\n2\n\n\n3144\n-2.836508\n-3.204013\n0.012610\n2\n\n\n3145\n-1.704158\n-10.621873\n2.024313\n2\n\n\n3146\n-2.467648\n-4.612999\n0.656284\n2\n\n\n\n\n\n3147 rows × 4 columns\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\npd.DataFrame(lrnr.model(XX)).assign(y=yy).query('y==0')\n\n\n  \n    \n      \n\n\n\n\n\n\n0\n1\n2\ny\n\n\n\n\n0\n0.981043\n-9.135092\n-1.149270\n0\n\n\n1\n-0.292905\n-4.281692\n-0.924575\n0\n\n\n2\n4.085316\n-9.199694\n-3.482234\n0\n\n\n3\n2.484926\n-9.336347\n-3.127304\n0\n\n\n4\n3.310040\n-12.257785\n-2.177761\n0\n\n\n...\n...\n...\n...\n...\n\n\n975\n0.432969\n-5.653580\n-1.944451\n0\n\n\n976\n2.685695\n-10.254354\n-2.466680\n0\n\n\n977\n2.474842\n-9.650204\n-2.452746\n0\n\n\n978\n1.268743\n-6.928779\n-1.419695\n0\n\n\n979\n4.371464\n-8.959077\n-4.056257\n0\n\n\n\n\n\n980 rows × 4 columns\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\n0으로 분류한 것들은 첫번째 열(0)의 값이 가장 큼\n\n\n\n\n\n이진 분류시에는 소프트맥스와 시그모이드 모두 activation function으로 사용할 수 있지만 소프트맥스를 사용하면 출력층이 2개가 되므로 파라미터 낭비가 심해진다.\n이진 분류시에는 시그모이드를 사용하는 것이 적합함.\n소프트맥스는 3개 이상을 분류해야 할 경우에 사용하면 됨\n\n\n\n\n\nfastai에서 지원\nfastai를 사용해 학습(lrnr.fit())을 할때 loss_value만 나오는 것이 아니라 error_rate과 정확도가 나오게 할 수 있는 옵션\ny의 형태를 주의해서 사용해야 함\n\n앞서 말한 것처럼 두 가지 타입이 있음\n\nvector + int\none-hot encoded vector + float\n\n\n\ntype 1) y의 형태가 vector + int일 때 - metrics = accuracy를 사용해야 함\n\n# train\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\nX = torch.concat([X0,X1])/255\n\n\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\ny.to(torch.int64).reshape(-1)\n\ntensor([0, 0, 0,  ..., 1, 1, 1])\n\n\n\n# test\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'testing/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'testing/1').ls()])\nXX = torch.concat([X0,X1])/255\n\n\nyy = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\nyy.to(torch.int64).reshape(-1)\n\ntensor([0, 0, 0,  ..., 1, 1, 1])\n\n\n\nds1 = torch.utils.data.TensorDataset(X,y.to(torch.int64).reshape(-1))\nds2 = torch.utils.data.TensorDataset(XX,yy.to(torch.int64).reshape(-1))\n\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=1266) \ndl2 = torch.utils.data.DataLoader(ds2,batch_size=2115) \n\ndls = DataLoaders(dl1,dl2) \n\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten(),\n    torch.nn.Linear(2304,2)\n)\nloss_fn = torch.nn.CrossEntropyLoss() \nlrnr = Learner(dls,net,loss_fn,metrics=[accuracy,error_rate])\n\n\nlrnr.fit(10)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\nerror_rate\ntime\n\n\n\n\n0\n1.128365\n0.601474\n0.463357\n0.536643\n00:00\n\n\n1\n0.684630\n0.304262\n0.975414\n0.024586\n00:00\n\n\n2\n0.503124\n0.144147\n0.989598\n0.010402\n00:00\n\n\n3\n0.373899\n0.068306\n0.996217\n0.003783\n00:00\n\n\n4\n0.281332\n0.040790\n0.996217\n0.003783\n00:00\n\n\n5\n0.215743\n0.026980\n0.996690\n0.003310\n00:00\n\n\n6\n0.168349\n0.019467\n0.996690\n0.003310\n00:00\n\n\n7\n0.133313\n0.014856\n0.998109\n0.001891\n00:00\n\n\n8\n0.106776\n0.011745\n0.998109\n0.001891\n00:00\n\n\n9\n0.086275\n0.009553\n0.999054\n0.000946\n00:00\n\n\n\n\n\ntype 2) y의 형태가 one-hot encoded vector + float일 때 - metrics = accuracy_multi를 사용해야 함 - error_rate는 사용못함\n\ny_onehot = torch.tensor(list(map(lambda x: [1.0,0.0] if x==0 else [0.0,1.0], y)))\nyy_onehot = torch.tensor(list(map(lambda x: [1.0,0.0] if x==0 else [0.0,1.0], yy)))\n\n\ny_onehot = torch.nn.functional.one_hot(y.reshape(-1).to(torch.int64)).to(torch.float32)\nyy_onehot = torch.nn.functional.one_hot(yy.reshape(-1).to(torch.int64)).to(torch.float32)\n\n\ntorch.nn.functional.one_hot() 함수 조건\n\n기본적으로 크기가 n인 벡터가 들어오길 기대\n정수가 들어오는 것을 기대\n\n하지만 원-핫 인코딩을 사용할 때에는 실수형으로 저장 되어야 하므로 마지막에 실수형으로 바꿔줘야 함\n\n\nds1 = torch.utils.data.TensorDataset(X,y_onehot)\nds2 = torch.utils.data.TensorDataset(XX,yy_onehot)\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=1266) \ndl2 = torch.utils.data.DataLoader(ds2,batch_size=2115) \ndls = DataLoaders(dl1,dl2) \n\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten(),\n    torch.nn.Linear(2304,2),\n    #torch.nn.Softmax()\n)\nloss_fn = torch.nn.CrossEntropyLoss() \nlrnr = Learner(dls,net,loss_fn,metrics=[accuracy_multi])\n\n\nlrnr.fit(10)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy_multi\ntime\n\n\n\n\n0\n1.213650\n0.647844\n0.463357\n00:00\n\n\n1\n0.744869\n0.384000\n0.933570\n00:00\n\n\n2\n0.571879\n0.187119\n0.986525\n00:00\n\n\n3\n0.432096\n0.090841\n0.994563\n00:00\n\n\n4\n0.326718\n0.048868\n0.995508\n00:00\n\n\n5\n0.250235\n0.028477\n0.996217\n00:00\n\n\n6\n0.194605\n0.018616\n0.996454\n00:00\n\n\n7\n0.153338\n0.013278\n0.996927\n00:00\n\n\n8\n0.122056\n0.010130\n0.997872\n00:00\n\n\n9\n0.097957\n0.008112\n0.998109\n00:00"
  },
  {
    "objectID": "about.html#about-this-blog",
    "href": "about.html#about-this-blog",
    "title": "JuWon Kwon",
    "section": "",
    "text": "This is the contents of the about page for my blog."
  },
  {
    "objectID": "about.html#about-me",
    "href": "about.html#about-me",
    "title": "JuWon Kwon",
    "section": "",
    "text": "바이오메디컬공학을 전공하고 있는 학부생 입니다.\n초음파와 딥러닝을 공부하고 있습니다."
  },
  {
    "objectID": "docs/DL/index.html",
    "href": "docs/DL/index.html",
    "title": "Quarto blog",
    "section": "",
    "text": "CNN\n\n\nCNN part1 test\n\n\n\n\nDL\n\n\nCNN\n\n\n\n\n\n\n\n\n\n\n\nFeb 13, 2022\n\n\nJuWon\n\n\n\n\n\n\n  \n\n\n\n\nTutorial\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "docs/DL/posts/DL_CNN.html",
    "href": "docs/DL/posts/DL_CNN.html",
    "title": "CNN",
    "section": "",
    "text": "toc:true\n\n\nimport torch \nimport torchvision\nfrom fastai.vision.all import * \nimport time\n\n\n\n간략하게 CNN의 구조를 설명하자면 - conv layer: 커널층(선형변환처럼 feature를 늘려주는 역할) - ReLU layer: 비선형을 추가해 표현력을 늘려주는 역할 - pooling layer: max 또는 avg를 통해 데이터를 요약해주는 역할\n\n\n\ntorch.manual_seed(43052)\n_conv = torch.nn.Conv2d(1,1,(2,2)) # 입력1, 출력1, (2,2) window size\n# (굳이 (2,2) 이런식으로 안해도 됨 어차피 윈도우 사이즈는 정사각행렬이므로 상수하나만 입력해도 됨됨)\n\n_X = torch.arange(0,25).float().reshape(1,5,5)\n_X\n\ntensor([[[ 0.,  1.,  2.,  3.,  4.],\n         [ 5.,  6.,  7.,  8.,  9.],\n         [10., 11., 12., 13., 14.],\n         [15., 16., 17., 18., 19.],\n         [20., 21., 22., 23., 24.]]])\n\n\n\n_conv.weight.data = torch.tensor([[[[0.25, 0.25],[0.25,0.25]]]])\n_conv.bias.data = torch.tensor([0.0])\n_conv.weight.data, _conv.bias.data\n\n(tensor([[[[0.2500, 0.2500],\n           [0.2500, 0.2500]]]]), tensor([0.]))\n\n\n\n_conv(_X)\n\ntensor([[[ 3.,  4.,  5.,  6.],\n         [ 8.,  9., 10., 11.],\n         [13., 14., 15., 16.],\n         [18., 19., 20., 21.]]], grad_fn=&lt;SqueezeBackward1&gt;)\n\n\nconv_tensor[1,1] = [[0, 1],[5, 6]]의 평균임을 알 수 있음 (conv.weight가 모두 1/4이어서 그런거임) - 해당 값은 (0 + 1 + 5 + 6) / 4 임을 알 수 있음 - 윈도우(커널)는 한 칸씩 움직이면서 weight를 곱하고 bias를 더함 - 첫 번째 3이라는 값은 [[0, 1],[5, 6]]에 conv을 적용 - 두 번째 4라는 값은 [[1, 2],[6, 7]]에 conv을 적용\n\n\n\n\n\n사실 ReLU는 DNN에서와 같이 음수는 0으로 양수는 그대로 되는 함수이다.\n\\(ReLU(x) = \\max(0,x)\\)\n\n\n\n\n\npooling layer에는 maxpooling이 있고 avgpooling이 있지만 이번에는 maxpooling을 다룰것임\nmaxpooling은 데이터 요약보다는 크기를 줄이는 느낌이 있음\n\n\n_maxpooling = torch.nn.MaxPool2d((2,2))\n_X = torch.arange(0,25).float().reshape(1,5,5)\n_X\n\ntensor([[[ 0.,  1.,  2.,  3.,  4.],\n         [ 5.,  6.,  7.,  8.,  9.],\n         [10., 11., 12., 13., 14.],\n         [15., 16., 17., 18., 19.],\n         [20., 21., 22., 23., 24.]]])\n\n\n\n_maxpooling(_X) \n\ntensor([[[ 6.,  8.],\n         [16., 18.]]])\n\n\n\nmaxpooling_tensor[1,1] = [[0, 1],[5, 6]] 중 가장 큰 값을 이므로 5이다.\npooling은 convlayer와 달리 pooling box가 겹치지 않게 움직임\n\n이러한 특성으로 인해 5번째 열과 행에 있는 값들은 pooling box에 들어가지 못해 버려지게 된다\n\n\n\n\n\n\n\npath = untar_data(URLs.MNIST)\n\n\n\n\n\n\n    \n      \n      100.03% [15687680/15683414 00:02&lt;00:00]\n    \n    \n\n\n\n\n\n(path/'원하는 경로').ls()\n\n\n\ntorchvision.io.read_image()\n해당 함수에 데이터 이름(이미지 이름)을 넣어주면 이미지를 tensor형태로 출력\n\n# train data\nx0 = torch.stack([torchvision.io.read_image(str(fnames)) for fnames in (path/'training/0').ls()])\nx1 = torch.stack([torchvision.io.read_image(str(fnames)) for fnames in (path/'training/1').ls()])\nx_tr = torch.concat([x0, x1])/255\n\ny_tr = torch.tensor([0.0]*len(x0) + [1.0]*len(x1)).reshape(-1,1)\n\n\n# train data\nx0 = torch.stack([torchvision.io.read_image(str(fnames)) for fnames in (path/'testing/0').ls()])\nx1 = torch.stack([torchvision.io.read_image(str(fnames)) for fnames in (path/'testing/1').ls()])\nx_test = torch.concat([x0, x1])/255\n\ny_test = torch.tensor([0.0]*len(x0) + [1.0]*len(x1)).reshape(-1,1)\n\n\nx_tr.shape, y_tr.shape, x_test.shape, y_test.shape\n\n(torch.Size([12665, 1, 28, 28]),\n torch.Size([12665, 1]),\n torch.Size([2115, 1, 28, 28]),\n torch.Size([2115, 1]))\n\n\n\n\n\n# conv\nc1 = torch.nn.Conv2d(1, 16 , 5) # 만약 color image였다면 입력 채널의 수를 3으로 지정해야 함\nx_tr.shape ,c1(x_tr).shape\n\n(torch.Size([12665, 1, 28, 28]), torch.Size([12665, 16, 24, 24]))\n\n\n\nsize계산 공식: 윈도우(커널)사이즈가 n이면 \\(size = height(width) - ( n - 1)\\)\n\n\n# ReLU\na1 = torch.nn.ReLU()\n\n\n# maxpooling\nm1 = torch.nn.MaxPool2d(2)\nprint(m1(a1(c1(x_tr))).shape)\n\ntorch.Size([12665, 16, 12, 12])\n\n\n\n행과 열이 2의 배수이므로 maxpool이 2일때는 버려지는 행과 열은 없다.\n\n\n# flatten(이미지를 한줄로 펼치는 것)\nf1 = torch.nn.Flatten()\nprint(f1(a1(m1(c1(x_tr)))).shape) #16 * 12 * 12 = 2304\n\ntorch.Size([12665, 2304])\n\n\n\n# sigmoid에 올리기 위해서는 2304 디멘젼을 1로 만들어야함\nl1=torch.nn.Linear(in_features=2304,out_features=1) \n\n\n# sigmoid (값이 0에서 1사이의 값, 즉 확률로 출력되도록)\na2 = torch.nn.Sigmoid()\nprint(a2(f1(a1(m1(c1(x_tr))))).shape)\n\ntorch.Size([12665, 2304])\n\n\n\nprint('이미지 사이즈:                     ', x_tr.shape)\nprint('conv:                              ',c1(x_tr).shape)\nprint('(ReLU) -&gt; maxpooling:              ',m1(a1(c1(x_tr))).shape)\nprint('이미지 펼치기:                     ',f1(a1(m1(c1(x_tr)))).shape)\nprint('이미지를 하나의 스칼라로 선형변환: ',l1(f1(a1(m1(c1(x_tr))))).shape)\nprint('시그모이드:                        ',a2(l1(f1(a1(m1(c1(x_tr)))))).shape)\n\n이미지 사이즈:                      torch.Size([12665, 1, 28, 28])\nconv:                               torch.Size([12665, 16, 24, 24])\n(ReLU) -&gt; maxpooling:               torch.Size([12665, 16, 12, 12])\n이미지 펼치기:                      torch.Size([12665, 2304])\n이미지를 하나의 스칼라로 선형변환:  torch.Size([12665, 1])\n시그모이드:                         torch.Size([12665, 1])\n\n\n\n\n\n\n원래라면 아래와 같은 코드를 사용하여 network를 학습시키겠지만 CNN과 같이 파라미터가 많은 network는 CPU로 연산시 학습할때 시간이 오래걸림\n\nloss_fn=torch.nn.BCELoss()\noptimizr= torch.optim.Adam(net.parameters())\nt1= time.time()\nfor epoc in range(100): \n    ## 1 \n    yhat=net(x_tr)\n    ## 2 \n    loss=loss_fn(yhat,y_tr) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\\(\\to\\) overview때 배운 fastai에 있는 데이터로더를 사용하면 GPU를 사용해 연산을 할 수 있다.\n\n# 데이터 로더에 들어갈 데이터세트 준비\nds_tr = torch.utils.data.TensorDataset(x_tr, y_tr)\nds_test = torch.utils.data.TensorDataset(x_test, y_test)\n\n\n데이터 로더는 배치크기를 지정해줘야 함\n\n\nlen(x_tr), len(x_test)\n\n(12665, 2115)\n\n\n\n데이터가 각각 12665, 2115개씩 들어가 있으므로 한번 업데이트할 때 총 데이터의 1 /10을 쓰도록 아래와 같이 배치 크기를 줌\n\nstochastic gradient descent(구용어: mini-batch gradient descent)\n\n\n\n# 데이터 로더\ndl_tr = torch.utils.data.DataLoader(ds_tr,batch_size=1266) \ndl_test = torch.utils.data.DataLoader(ds_test,batch_size=2115) \n\n\ndls = DataLoaders(dl_tr,dl_test)\n\n\nnet = torch.nn.Sequential(\n    # conv layer \n    c1, \n    # ReLU\n    a1, \n    # maxpool\n    m1, \n    # flatten\n    f1, \n    # linear transform (n -&gt; 1)\n    l1,\n    # Sigmoid\n    a2\n)\n\nloss_fn=torch.nn.BCELoss()\n\n\nlrnr = Learner(dls,net,loss_fn) # fastai의 Learner는 오미타이저의 기본값이 adam이므로 따로 지정해주지 않아도 됨\n\n\nlrnr.fit(10)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n0.979273\n0.639250\n00:05\n\n\n1\n0.703008\n0.402466\n00:00\n\n\n2\n0.547401\n0.256881\n00:00\n\n\n3\n0.434025\n0.142217\n00:00\n\n\n4\n0.340996\n0.079636\n00:00\n\n\n5\n0.267902\n0.048050\n00:00\n\n\n6\n0.211895\n0.031742\n00:00\n\n\n7\n0.169176\n0.022921\n00:00\n\n\n8\n0.136331\n0.017658\n00:00\n\n\n9\n0.110770\n0.014233\n00:00\n\n\n\n\n\n\nLearner 오브젝트에 들어간 net은 gpu상에 있도록 되어있음 &gt; python    net[0].weight 위 코드를 출력하면 weight tensor가 출력되는데 가장 밑을 확인하면 device = ’cuda:0’라는 것이 있음. 이는 해당 tensor가 gpu상에 위치해있는 것을 의미한다.\n+ tensor 연산을 할 때에는 모든 tensor가 같은 곳에 위치해있어야 한다.\n\n\nnet = net.to('cpu')\nplt.plot(net(x_tr).data,'.')\nplt.title(\"Training Set\",size=15)\n\nText(0.5, 1.0, 'Training Set')\n\n\n\n\n\n\nplt.plot(net(x_test).data,'.')\nplt.title(\"Testing Set\",size=15)\n\nText(0.5, 1.0, 'Testing Set')\n\n\n\n\n\n\n\n\n\n\n\n\nBCEWithLogitsLoss = Sigmoid + BCELoss\n손실함수로 이를 사용하면 network 마지막에 시그모이드 함수를 추가하지 않아도 됨\n이를 사용하면 수치적으로 더 안정이 된다는 장점이 있음\n\n\n\n\n\n\n다중(k개) 클래스를 분류 - LossFunction: CrossEntrophyLoss\n- ActivationFunction: SoftmaxFunction - 마지막 출력층: torch.nn.Linear(n, k)\n\n\n\n\n소프트맥스 함수가 계산하는 과정은 아래와 같음 (3개를 분류할 경우) \\(softmax=\\frac{e^{a 또는 b 또는 c}}{e^{a} + e^{b} + e^{c}}\\)\n\n\n\n\n\nk개의 클래스를 분류하는 모델의 Loss 계산 방법\n\nsftmax(_netout) # -&gt; 0 ~ 1 사이의 값 k개 출력\n\ntorch.log(sftmax(_netout)) # -&gt; 0 ~ 1사이의 값을 로그에 넣게 되면 -∞ ~ 0사이의 값 k개 출력\n\n- torch.log(sftmax(_netout)) * _y_onehot \n# 만약 값이 log(sftmax(_netout)) = [-2.2395, -2.2395, -0.2395] 이렇게 나오고 \n#y_onehot이 [1, 0, 0]이라면 해당 코드의 결과, 즉 loss는 2.2395이 된다. \n\n만약 모델이 첫 번째 값이 확실하게 정답이라고 생각한다면 로그의 결과값은 0이 된다 -&gt; 해당 값이 정답일경우 0 * 1 = 0이므로 loss는 0이 된다\n최종적으로는 위 코드를 통해 얻은 Loss를 평균을 내어 출력한다.\n\n+ 위의 설명은 정답이 원-핫 인코딩 형식으로 되어있을 때의 Loss계산 방법임\n+ 정답이 vector + 정수형으로 되어 있을 때의 Loss계산 방법은 잘 모르겠음\n\n\n\n\ntype 1) int형을 사용하는 방법 (vector)\ntype 2) float형을 사용하는 방법 (one-hot encoded vector)\n만약 사슴, 강아지, 고양이를 분류하는 모델이라면\n\ntype 1)의 경우 &lt;사슴: 0, 강아지: 1, 고양이: 2&gt; (단, 데이터 형태는는 int(정수))\ntype 2)의 경우 &lt;사슴: [1, 0, 0], 강아지: [0, 1, 0], 고양이: [0, 0, 1] &gt; (단, 데이터의 형태는 float(실수))\n\n\n\n\n\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\n\n\ntorch.tensor([0]*len(X0) + [1]*len(X1))#.reshape(-1,1)\n\ntensor([0, 0, 0,  ..., 1, 1, 1])\n\n\n\n\n\n\nyy = torch.tensor([0]*len(X0) + [1]*len(X1))#.reshape(-1,1)\ntorch.nn.functional.one_hot(yy).float()\n\ntensor([[1., 0.],\n        [1., 0.],\n        [1., 0.],\n        ...,\n        [0., 1.],\n        [0., 1.],\n        [0., 1.]])\n\n\n\n\n\n\n\n# train\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\nX2 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/2').ls()])\nX = torch.concat([X0,X1,X2])/255\ny = torch.tensor([0]*len(X0) + [1]*len(X1)+ [2]*len(X2))#.reshape(-1,1)\n\n\n# test\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'testing/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'testing/1').ls()])\nX2 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'testing/2').ls()])\nXX = torch.concat([X0,X1,X2])/255\nyy = torch.tensor([0]*len(X0) + [1]*len(X1)+ [2]*len(X2))#.reshape(-1,1)\n\n\nlen(X) # 18623\n\n18623\n\n\n\nds1 = torch.utils.data.TensorDataset(X,y) \nds2 = torch.utils.data.TensorDataset(XX,yy) \ndl1 = torch.utils.data.DataLoader(ds1,batch_size=1862) # 에폭당 11번= 1862 꽉 채워서 10번하고 3개정도 남은 걸로 한 번\ndl2 = torch.utils.data.DataLoader(ds2,batch_size=3147) # test는 전부다 넣어서\ndls = DataLoaders(dl1,dl2) \n\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten(),\n    torch.nn.Linear(2304,3) # 0,1,2 3개를 구분하는 문제이므로 out_features=3 \n)\n\nloss_fn = torch.nn.CrossEntropyLoss() # 여기에는 softmax함수가 내장되어 있음 \n#-&gt; net마지막에 softmax를 넣으면 안됨\n# BCEWithLogitsLoss 느낌(시그모이드 + BCE)\n\n\nlrnr = Learner(dls,net,loss_fn) # 옵티마이저는 아답이 디폴트 값이어서 굳이 안넣어도 됨\n\n\nlrnr.fit(10) \n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n1.797101\n1.103916\n00:00\n\n\n1\n1.267011\n0.823797\n00:00\n\n\n2\n1.055513\n0.667210\n00:00\n\n\n3\n0.910746\n0.435414\n00:00\n\n\n4\n0.762887\n0.284001\n00:00\n\n\n5\n0.625515\n0.199502\n00:00\n\n\n6\n0.515352\n0.152906\n00:00\n\n\n7\n0.429145\n0.123678\n00:00\n\n\n8\n0.359694\n0.105466\n00:00\n\n\n9\n0.303888\n0.092883\n00:00\n\n\n\n\n\n\nlrnr.model.to(\"cpu\")\n\npd.DataFrame(lrnr.model(XX)).assign(y=yy) \n\n\n  \n    \n      \n\n\n\n\n\n\n0\n1\n2\ny\n\n\n\n\n0\n0.981043\n-9.135092\n-1.149270\n0\n\n\n1\n-0.292905\n-4.281692\n-0.924575\n0\n\n\n2\n4.085316\n-9.199694\n-3.482234\n0\n\n\n3\n2.484926\n-9.336347\n-3.127304\n0\n\n\n4\n3.310040\n-12.257785\n-2.177761\n0\n\n\n...\n...\n...\n...\n...\n\n\n3142\n-1.138366\n-5.435792\n0.370670\n2\n\n\n3143\n-4.458741\n-4.281343\n2.052410\n2\n\n\n3144\n-2.836508\n-3.204013\n0.012610\n2\n\n\n3145\n-1.704158\n-10.621873\n2.024313\n2\n\n\n3146\n-2.467648\n-4.612999\n0.656284\n2\n\n\n\n\n\n3147 rows × 4 columns\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\npd.DataFrame(lrnr.model(XX)).assign(y=yy).query('y==0')\n\n\n  \n    \n      \n\n\n\n\n\n\n0\n1\n2\ny\n\n\n\n\n0\n0.981043\n-9.135092\n-1.149270\n0\n\n\n1\n-0.292905\n-4.281692\n-0.924575\n0\n\n\n2\n4.085316\n-9.199694\n-3.482234\n0\n\n\n3\n2.484926\n-9.336347\n-3.127304\n0\n\n\n4\n3.310040\n-12.257785\n-2.177761\n0\n\n\n...\n...\n...\n...\n...\n\n\n975\n0.432969\n-5.653580\n-1.944451\n0\n\n\n976\n2.685695\n-10.254354\n-2.466680\n0\n\n\n977\n2.474842\n-9.650204\n-2.452746\n0\n\n\n978\n1.268743\n-6.928779\n-1.419695\n0\n\n\n979\n4.371464\n-8.959077\n-4.056257\n0\n\n\n\n\n\n980 rows × 4 columns\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\n0으로 분류한 것들은 첫번째 열(0)의 값이 가장 큼\n\n\n\n\n\n이진 분류시에는 소프트맥스와 시그모이드 모두 activation function으로 사용할 수 있지만 소프트맥스를 사용하면 출력층이 2개가 되므로 파라미터 낭비가 심해진다.\n이진 분류시에는 시그모이드를 사용하는 것이 적합함.\n소프트맥스는 3개 이상을 분류해야 할 경우에 사용하면 됨\n\n\n\n\n\nfastai에서 지원\nfastai를 사용해 학습(lrnr.fit())을 할때 loss_value만 나오는 것이 아니라 error_rate과 정확도가 나오게 할 수 있는 옵션\ny의 형태를 주의해서 사용해야 함\n\n앞서 말한 것처럼 두 가지 타입이 있음\n\nvector + int\none-hot encoded vector + float\n\n\n\ntype 1) y의 형태가 vector + int일 때 - metrics = accuracy를 사용해야 함\n\n# train\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\nX = torch.concat([X0,X1])/255\n\n\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\ny.to(torch.int64).reshape(-1)\n\ntensor([0, 0, 0,  ..., 1, 1, 1])\n\n\n\n# test\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'testing/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'testing/1').ls()])\nXX = torch.concat([X0,X1])/255\n\n\nyy = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\nyy.to(torch.int64).reshape(-1)\n\ntensor([0, 0, 0,  ..., 1, 1, 1])\n\n\n\nds1 = torch.utils.data.TensorDataset(X,y.to(torch.int64).reshape(-1))\nds2 = torch.utils.data.TensorDataset(XX,yy.to(torch.int64).reshape(-1))\n\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=1266) \ndl2 = torch.utils.data.DataLoader(ds2,batch_size=2115) \n\ndls = DataLoaders(dl1,dl2) \n\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten(),\n    torch.nn.Linear(2304,2)\n)\nloss_fn = torch.nn.CrossEntropyLoss() \nlrnr = Learner(dls,net,loss_fn,metrics=[accuracy,error_rate])\n\n\nlrnr.fit(10)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\nerror_rate\ntime\n\n\n\n\n0\n1.128365\n0.601474\n0.463357\n0.536643\n00:00\n\n\n1\n0.684630\n0.304262\n0.975414\n0.024586\n00:00\n\n\n2\n0.503124\n0.144147\n0.989598\n0.010402\n00:00\n\n\n3\n0.373899\n0.068306\n0.996217\n0.003783\n00:00\n\n\n4\n0.281332\n0.040790\n0.996217\n0.003783\n00:00\n\n\n5\n0.215743\n0.026980\n0.996690\n0.003310\n00:00\n\n\n6\n0.168349\n0.019467\n0.996690\n0.003310\n00:00\n\n\n7\n0.133313\n0.014856\n0.998109\n0.001891\n00:00\n\n\n8\n0.106776\n0.011745\n0.998109\n0.001891\n00:00\n\n\n9\n0.086275\n0.009553\n0.999054\n0.000946\n00:00\n\n\n\n\n\ntype 2) y의 형태가 one-hot encoded vector + float일 때 - metrics = accuracy_multi를 사용해야 함 - error_rate는 사용못함\n\ny_onehot = torch.tensor(list(map(lambda x: [1.0,0.0] if x==0 else [0.0,1.0], y)))\nyy_onehot = torch.tensor(list(map(lambda x: [1.0,0.0] if x==0 else [0.0,1.0], yy)))\n\n\ny_onehot = torch.nn.functional.one_hot(y.reshape(-1).to(torch.int64)).to(torch.float32)\nyy_onehot = torch.nn.functional.one_hot(yy.reshape(-1).to(torch.int64)).to(torch.float32)\n\n\ntorch.nn.functional.one_hot() 함수 조건\n\n기본적으로 크기가 n인 벡터가 들어오길 기대\n정수가 들어오는 것을 기대\n\n하지만 원-핫 인코딩을 사용할 때에는 실수형으로 저장 되어야 하므로 마지막에 실수형으로 바꿔줘야 함\n\n\nds1 = torch.utils.data.TensorDataset(X,y_onehot)\nds2 = torch.utils.data.TensorDataset(XX,yy_onehot)\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=1266) \ndl2 = torch.utils.data.DataLoader(ds2,batch_size=2115) \ndls = DataLoaders(dl1,dl2) \n\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten(),\n    torch.nn.Linear(2304,2),\n    #torch.nn.Softmax()\n)\nloss_fn = torch.nn.CrossEntropyLoss() \nlrnr = Learner(dls,net,loss_fn,metrics=[accuracy_multi])\n\n\nlrnr.fit(10)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy_multi\ntime\n\n\n\n\n0\n1.213650\n0.647844\n0.463357\n00:00\n\n\n1\n0.744869\n0.384000\n0.933570\n00:00\n\n\n2\n0.571879\n0.187119\n0.986525\n00:00\n\n\n3\n0.432096\n0.090841\n0.994563\n00:00\n\n\n4\n0.326718\n0.048868\n0.995508\n00:00\n\n\n5\n0.250235\n0.028477\n0.996217\n00:00\n\n\n6\n0.194605\n0.018616\n0.996454\n00:00\n\n\n7\n0.153338\n0.013278\n0.996927\n00:00\n\n\n8\n0.122056\n0.010130\n0.997872\n00:00\n\n\n9\n0.097957\n0.008112\n0.998109\n00:00"
  },
  {
    "objectID": "docs/DL/posts/DL_CNN.html#cnn-구조",
    "href": "docs/DL/posts/DL_CNN.html#cnn-구조",
    "title": "CNN",
    "section": "",
    "text": "간략하게 CNN의 구조를 설명하자면 - conv layer: 커널층(선형변환처럼 feature를 늘려주는 역할) - ReLU layer: 비선형을 추가해 표현력을 늘려주는 역할 - pooling layer: max 또는 avg를 통해 데이터를 요약해주는 역할\n\n\n\ntorch.manual_seed(43052)\n_conv = torch.nn.Conv2d(1,1,(2,2)) # 입력1, 출력1, (2,2) window size\n# (굳이 (2,2) 이런식으로 안해도 됨 어차피 윈도우 사이즈는 정사각행렬이므로 상수하나만 입력해도 됨됨)\n\n_X = torch.arange(0,25).float().reshape(1,5,5)\n_X\n\ntensor([[[ 0.,  1.,  2.,  3.,  4.],\n         [ 5.,  6.,  7.,  8.,  9.],\n         [10., 11., 12., 13., 14.],\n         [15., 16., 17., 18., 19.],\n         [20., 21., 22., 23., 24.]]])\n\n\n\n_conv.weight.data = torch.tensor([[[[0.25, 0.25],[0.25,0.25]]]])\n_conv.bias.data = torch.tensor([0.0])\n_conv.weight.data, _conv.bias.data\n\n(tensor([[[[0.2500, 0.2500],\n           [0.2500, 0.2500]]]]), tensor([0.]))\n\n\n\n_conv(_X)\n\ntensor([[[ 3.,  4.,  5.,  6.],\n         [ 8.,  9., 10., 11.],\n         [13., 14., 15., 16.],\n         [18., 19., 20., 21.]]], grad_fn=&lt;SqueezeBackward1&gt;)\n\n\nconv_tensor[1,1] = [[0, 1],[5, 6]]의 평균임을 알 수 있음 (conv.weight가 모두 1/4이어서 그런거임) - 해당 값은 (0 + 1 + 5 + 6) / 4 임을 알 수 있음 - 윈도우(커널)는 한 칸씩 움직이면서 weight를 곱하고 bias를 더함 - 첫 번째 3이라는 값은 [[0, 1],[5, 6]]에 conv을 적용 - 두 번째 4라는 값은 [[1, 2],[6, 7]]에 conv을 적용\n\n\n\n\n\n사실 ReLU는 DNN에서와 같이 음수는 0으로 양수는 그대로 되는 함수이다.\n\\(ReLU(x) = \\max(0,x)\\)\n\n\n\n\n\npooling layer에는 maxpooling이 있고 avgpooling이 있지만 이번에는 maxpooling을 다룰것임\nmaxpooling은 데이터 요약보다는 크기를 줄이는 느낌이 있음\n\n\n_maxpooling = torch.nn.MaxPool2d((2,2))\n_X = torch.arange(0,25).float().reshape(1,5,5)\n_X\n\ntensor([[[ 0.,  1.,  2.,  3.,  4.],\n         [ 5.,  6.,  7.,  8.,  9.],\n         [10., 11., 12., 13., 14.],\n         [15., 16., 17., 18., 19.],\n         [20., 21., 22., 23., 24.]]])\n\n\n\n_maxpooling(_X) \n\ntensor([[[ 6.,  8.],\n         [16., 18.]]])\n\n\n\nmaxpooling_tensor[1,1] = [[0, 1],[5, 6]] 중 가장 큰 값을 이므로 5이다.\npooling은 convlayer와 달리 pooling box가 겹치지 않게 움직임\n\n이러한 특성으로 인해 5번째 열과 행에 있는 값들은 pooling box에 들어가지 못해 버려지게 된다"
  },
  {
    "objectID": "docs/DL/posts/DL_CNN.html#cnn-구현",
    "href": "docs/DL/posts/DL_CNN.html#cnn-구현",
    "title": "CNN",
    "section": "",
    "text": "path = untar_data(URLs.MNIST)\n\n\n\n\n\n\n    \n      \n      100.03% [15687680/15683414 00:02&lt;00:00]"
  },
  {
    "objectID": "docs/DL/posts/DL_CNN.html#path-사용법-데이터-준비",
    "href": "docs/DL/posts/DL_CNN.html#path-사용법-데이터-준비",
    "title": "CNN",
    "section": "",
    "text": "(path/'원하는 경로').ls()"
  },
  {
    "objectID": "docs/DL/posts/DL_CNN.html#위-코드를-사용하면-폴더-안에-있는-데이터들의-이름을-출력",
    "href": "docs/DL/posts/DL_CNN.html#위-코드를-사용하면-폴더-안에-있는-데이터들의-이름을-출력",
    "title": "CNN",
    "section": "",
    "text": "torchvision.io.read_image()\n해당 함수에 데이터 이름(이미지 이름)을 넣어주면 이미지를 tensor형태로 출력\n\n# train data\nx0 = torch.stack([torchvision.io.read_image(str(fnames)) for fnames in (path/'training/0').ls()])\nx1 = torch.stack([torchvision.io.read_image(str(fnames)) for fnames in (path/'training/1').ls()])\nx_tr = torch.concat([x0, x1])/255\n\ny_tr = torch.tensor([0.0]*len(x0) + [1.0]*len(x1)).reshape(-1,1)\n\n\n# train data\nx0 = torch.stack([torchvision.io.read_image(str(fnames)) for fnames in (path/'testing/0').ls()])\nx1 = torch.stack([torchvision.io.read_image(str(fnames)) for fnames in (path/'testing/1').ls()])\nx_test = torch.concat([x0, x1])/255\n\ny_test = torch.tensor([0.0]*len(x0) + [1.0]*len(x1)).reshape(-1,1)\n\n\nx_tr.shape, y_tr.shape, x_test.shape, y_test.shape\n\n(torch.Size([12665, 1, 28, 28]),\n torch.Size([12665, 1]),\n torch.Size([2115, 1, 28, 28]),\n torch.Size([2115, 1]))\n\n\n\n\n\n# conv\nc1 = torch.nn.Conv2d(1, 16 , 5) # 만약 color image였다면 입력 채널의 수를 3으로 지정해야 함\nx_tr.shape ,c1(x_tr).shape\n\n(torch.Size([12665, 1, 28, 28]), torch.Size([12665, 16, 24, 24]))\n\n\n\nsize계산 공식: 윈도우(커널)사이즈가 n이면 \\(size = height(width) - ( n - 1)\\)\n\n\n# ReLU\na1 = torch.nn.ReLU()\n\n\n# maxpooling\nm1 = torch.nn.MaxPool2d(2)\nprint(m1(a1(c1(x_tr))).shape)\n\ntorch.Size([12665, 16, 12, 12])\n\n\n\n행과 열이 2의 배수이므로 maxpool이 2일때는 버려지는 행과 열은 없다.\n\n\n# flatten(이미지를 한줄로 펼치는 것)\nf1 = torch.nn.Flatten()\nprint(f1(a1(m1(c1(x_tr)))).shape) #16 * 12 * 12 = 2304\n\ntorch.Size([12665, 2304])\n\n\n\n# sigmoid에 올리기 위해서는 2304 디멘젼을 1로 만들어야함\nl1=torch.nn.Linear(in_features=2304,out_features=1) \n\n\n# sigmoid (값이 0에서 1사이의 값, 즉 확률로 출력되도록)\na2 = torch.nn.Sigmoid()\nprint(a2(f1(a1(m1(c1(x_tr))))).shape)\n\ntorch.Size([12665, 2304])\n\n\n\nprint('이미지 사이즈:                     ', x_tr.shape)\nprint('conv:                              ',c1(x_tr).shape)\nprint('(ReLU) -&gt; maxpooling:              ',m1(a1(c1(x_tr))).shape)\nprint('이미지 펼치기:                     ',f1(a1(m1(c1(x_tr)))).shape)\nprint('이미지를 하나의 스칼라로 선형변환: ',l1(f1(a1(m1(c1(x_tr))))).shape)\nprint('시그모이드:                        ',a2(l1(f1(a1(m1(c1(x_tr)))))).shape)\n\n이미지 사이즈:                      torch.Size([12665, 1, 28, 28])\nconv:                               torch.Size([12665, 16, 24, 24])\n(ReLU) -&gt; maxpooling:               torch.Size([12665, 16, 12, 12])\n이미지 펼치기:                      torch.Size([12665, 2304])\n이미지를 하나의 스칼라로 선형변환:  torch.Size([12665, 1])\n시그모이드:                         torch.Size([12665, 1])\n\n\n\n\n\n\n원래라면 아래와 같은 코드를 사용하여 network를 학습시키겠지만 CNN과 같이 파라미터가 많은 network는 CPU로 연산시 학습할때 시간이 오래걸림\n\nloss_fn=torch.nn.BCELoss()\noptimizr= torch.optim.Adam(net.parameters())\nt1= time.time()\nfor epoc in range(100): \n    ## 1 \n    yhat=net(x_tr)\n    ## 2 \n    loss=loss_fn(yhat,y_tr) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\\(\\to\\) overview때 배운 fastai에 있는 데이터로더를 사용하면 GPU를 사용해 연산을 할 수 있다.\n\n# 데이터 로더에 들어갈 데이터세트 준비\nds_tr = torch.utils.data.TensorDataset(x_tr, y_tr)\nds_test = torch.utils.data.TensorDataset(x_test, y_test)\n\n\n데이터 로더는 배치크기를 지정해줘야 함\n\n\nlen(x_tr), len(x_test)\n\n(12665, 2115)\n\n\n\n데이터가 각각 12665, 2115개씩 들어가 있으므로 한번 업데이트할 때 총 데이터의 1 /10을 쓰도록 아래와 같이 배치 크기를 줌\n\nstochastic gradient descent(구용어: mini-batch gradient descent)\n\n\n\n# 데이터 로더\ndl_tr = torch.utils.data.DataLoader(ds_tr,batch_size=1266) \ndl_test = torch.utils.data.DataLoader(ds_test,batch_size=2115) \n\n\ndls = DataLoaders(dl_tr,dl_test)\n\n\nnet = torch.nn.Sequential(\n    # conv layer \n    c1, \n    # ReLU\n    a1, \n    # maxpool\n    m1, \n    # flatten\n    f1, \n    # linear transform (n -&gt; 1)\n    l1,\n    # Sigmoid\n    a2\n)\n\nloss_fn=torch.nn.BCELoss()\n\n\nlrnr = Learner(dls,net,loss_fn) # fastai의 Learner는 오미타이저의 기본값이 adam이므로 따로 지정해주지 않아도 됨\n\n\nlrnr.fit(10)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n0.979273\n0.639250\n00:05\n\n\n1\n0.703008\n0.402466\n00:00\n\n\n2\n0.547401\n0.256881\n00:00\n\n\n3\n0.434025\n0.142217\n00:00\n\n\n4\n0.340996\n0.079636\n00:00\n\n\n5\n0.267902\n0.048050\n00:00\n\n\n6\n0.211895\n0.031742\n00:00\n\n\n7\n0.169176\n0.022921\n00:00\n\n\n8\n0.136331\n0.017658\n00:00\n\n\n9\n0.110770\n0.014233\n00:00\n\n\n\n\n\n\nLearner 오브젝트에 들어간 net은 gpu상에 있도록 되어있음 &gt; python    net[0].weight 위 코드를 출력하면 weight tensor가 출력되는데 가장 밑을 확인하면 device = ’cuda:0’라는 것이 있음. 이는 해당 tensor가 gpu상에 위치해있는 것을 의미한다.\n+ tensor 연산을 할 때에는 모든 tensor가 같은 곳에 위치해있어야 한다.\n\n\nnet = net.to('cpu')\nplt.plot(net(x_tr).data,'.')\nplt.title(\"Training Set\",size=15)\n\nText(0.5, 1.0, 'Training Set')\n\n\n\n\n\n\nplt.plot(net(x_test).data,'.')\nplt.title(\"Testing Set\",size=15)\n\nText(0.5, 1.0, 'Testing Set')"
  },
  {
    "objectID": "docs/DL/posts/DL_CNN.html#loss-function",
    "href": "docs/DL/posts/DL_CNN.html#loss-function",
    "title": "CNN",
    "section": "",
    "text": "BCEWithLogitsLoss = Sigmoid + BCELoss\n손실함수로 이를 사용하면 network 마지막에 시그모이드 함수를 추가하지 않아도 됨\n이를 사용하면 수치적으로 더 안정이 된다는 장점이 있음"
  },
  {
    "objectID": "docs/DL/posts/DL_CNN.html#k개의-클래스를-분류하는-모델",
    "href": "docs/DL/posts/DL_CNN.html#k개의-클래스를-분류하는-모델",
    "title": "CNN",
    "section": "",
    "text": "다중(k개) 클래스를 분류 - LossFunction: CrossEntrophyLoss\n- ActivationFunction: SoftmaxFunction - 마지막 출력층: torch.nn.Linear(n, k)\n\n\n\n\n소프트맥스 함수가 계산하는 과정은 아래와 같음 (3개를 분류할 경우) \\(softmax=\\frac{e^{a 또는 b 또는 c}}{e^{a} + e^{b} + e^{c}}\\)\n\n\n\n\n\nk개의 클래스를 분류하는 모델의 Loss 계산 방법\n\nsftmax(_netout) # -&gt; 0 ~ 1 사이의 값 k개 출력\n\ntorch.log(sftmax(_netout)) # -&gt; 0 ~ 1사이의 값을 로그에 넣게 되면 -∞ ~ 0사이의 값 k개 출력\n\n- torch.log(sftmax(_netout)) * _y_onehot \n# 만약 값이 log(sftmax(_netout)) = [-2.2395, -2.2395, -0.2395] 이렇게 나오고 \n#y_onehot이 [1, 0, 0]이라면 해당 코드의 결과, 즉 loss는 2.2395이 된다. \n\n만약 모델이 첫 번째 값이 확실하게 정답이라고 생각한다면 로그의 결과값은 0이 된다 -&gt; 해당 값이 정답일경우 0 * 1 = 0이므로 loss는 0이 된다\n최종적으로는 위 코드를 통해 얻은 Loss를 평균을 내어 출력한다.\n\n+ 위의 설명은 정답이 원-핫 인코딩 형식으로 되어있을 때의 Loss계산 방법임\n+ 정답이 vector + 정수형으로 되어 있을 때의 Loss계산 방법은 잘 모르겠음\n\n\n\n\ntype 1) int형을 사용하는 방법 (vector)\ntype 2) float형을 사용하는 방법 (one-hot encoded vector)\n만약 사슴, 강아지, 고양이를 분류하는 모델이라면\n\ntype 1)의 경우 &lt;사슴: 0, 강아지: 1, 고양이: 2&gt; (단, 데이터 형태는는 int(정수))\ntype 2)의 경우 &lt;사슴: [1, 0, 0], 강아지: [0, 1, 0], 고양이: [0, 0, 1] &gt; (단, 데이터의 형태는 float(실수))\n\n\n\n\n\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\n\n\ntorch.tensor([0]*len(X0) + [1]*len(X1))#.reshape(-1,1)\n\ntensor([0, 0, 0,  ..., 1, 1, 1])\n\n\n\n\n\n\nyy = torch.tensor([0]*len(X0) + [1]*len(X1))#.reshape(-1,1)\ntorch.nn.functional.one_hot(yy).float()\n\ntensor([[1., 0.],\n        [1., 0.],\n        [1., 0.],\n        ...,\n        [0., 1.],\n        [0., 1.],\n        [0., 1.]])\n\n\n\n\n\n\n\n# train\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\nX2 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/2').ls()])\nX = torch.concat([X0,X1,X2])/255\ny = torch.tensor([0]*len(X0) + [1]*len(X1)+ [2]*len(X2))#.reshape(-1,1)\n\n\n# test\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'testing/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'testing/1').ls()])\nX2 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'testing/2').ls()])\nXX = torch.concat([X0,X1,X2])/255\nyy = torch.tensor([0]*len(X0) + [1]*len(X1)+ [2]*len(X2))#.reshape(-1,1)\n\n\nlen(X) # 18623\n\n18623\n\n\n\nds1 = torch.utils.data.TensorDataset(X,y) \nds2 = torch.utils.data.TensorDataset(XX,yy) \ndl1 = torch.utils.data.DataLoader(ds1,batch_size=1862) # 에폭당 11번= 1862 꽉 채워서 10번하고 3개정도 남은 걸로 한 번\ndl2 = torch.utils.data.DataLoader(ds2,batch_size=3147) # test는 전부다 넣어서\ndls = DataLoaders(dl1,dl2) \n\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten(),\n    torch.nn.Linear(2304,3) # 0,1,2 3개를 구분하는 문제이므로 out_features=3 \n)\n\nloss_fn = torch.nn.CrossEntropyLoss() # 여기에는 softmax함수가 내장되어 있음 \n#-&gt; net마지막에 softmax를 넣으면 안됨\n# BCEWithLogitsLoss 느낌(시그모이드 + BCE)\n\n\nlrnr = Learner(dls,net,loss_fn) # 옵티마이저는 아답이 디폴트 값이어서 굳이 안넣어도 됨\n\n\nlrnr.fit(10) \n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n1.797101\n1.103916\n00:00\n\n\n1\n1.267011\n0.823797\n00:00\n\n\n2\n1.055513\n0.667210\n00:00\n\n\n3\n0.910746\n0.435414\n00:00\n\n\n4\n0.762887\n0.284001\n00:00\n\n\n5\n0.625515\n0.199502\n00:00\n\n\n6\n0.515352\n0.152906\n00:00\n\n\n7\n0.429145\n0.123678\n00:00\n\n\n8\n0.359694\n0.105466\n00:00\n\n\n9\n0.303888\n0.092883\n00:00\n\n\n\n\n\n\nlrnr.model.to(\"cpu\")\n\npd.DataFrame(lrnr.model(XX)).assign(y=yy) \n\n\n  \n    \n      \n\n\n\n\n\n\n0\n1\n2\ny\n\n\n\n\n0\n0.981043\n-9.135092\n-1.149270\n0\n\n\n1\n-0.292905\n-4.281692\n-0.924575\n0\n\n\n2\n4.085316\n-9.199694\n-3.482234\n0\n\n\n3\n2.484926\n-9.336347\n-3.127304\n0\n\n\n4\n3.310040\n-12.257785\n-2.177761\n0\n\n\n...\n...\n...\n...\n...\n\n\n3142\n-1.138366\n-5.435792\n0.370670\n2\n\n\n3143\n-4.458741\n-4.281343\n2.052410\n2\n\n\n3144\n-2.836508\n-3.204013\n0.012610\n2\n\n\n3145\n-1.704158\n-10.621873\n2.024313\n2\n\n\n3146\n-2.467648\n-4.612999\n0.656284\n2\n\n\n\n\n\n3147 rows × 4 columns\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\npd.DataFrame(lrnr.model(XX)).assign(y=yy).query('y==0')\n\n\n  \n    \n      \n\n\n\n\n\n\n0\n1\n2\ny\n\n\n\n\n0\n0.981043\n-9.135092\n-1.149270\n0\n\n\n1\n-0.292905\n-4.281692\n-0.924575\n0\n\n\n2\n4.085316\n-9.199694\n-3.482234\n0\n\n\n3\n2.484926\n-9.336347\n-3.127304\n0\n\n\n4\n3.310040\n-12.257785\n-2.177761\n0\n\n\n...\n...\n...\n...\n...\n\n\n975\n0.432969\n-5.653580\n-1.944451\n0\n\n\n976\n2.685695\n-10.254354\n-2.466680\n0\n\n\n977\n2.474842\n-9.650204\n-2.452746\n0\n\n\n978\n1.268743\n-6.928779\n-1.419695\n0\n\n\n979\n4.371464\n-8.959077\n-4.056257\n0\n\n\n\n\n\n980 rows × 4 columns\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\n0으로 분류한 것들은 첫번째 열(0)의 값이 가장 큼\n\n\n\n\n\n이진 분류시에는 소프트맥스와 시그모이드 모두 activation function으로 사용할 수 있지만 소프트맥스를 사용하면 출력층이 2개가 되므로 파라미터 낭비가 심해진다.\n이진 분류시에는 시그모이드를 사용하는 것이 적합함.\n소프트맥스는 3개 이상을 분류해야 할 경우에 사용하면 됨\n\n\n\n\n\nfastai에서 지원\nfastai를 사용해 학습(lrnr.fit())을 할때 loss_value만 나오는 것이 아니라 error_rate과 정확도가 나오게 할 수 있는 옵션\ny의 형태를 주의해서 사용해야 함\n\n앞서 말한 것처럼 두 가지 타입이 있음\n\nvector + int\none-hot encoded vector + float\n\n\n\ntype 1) y의 형태가 vector + int일 때 - metrics = accuracy를 사용해야 함\n\n# train\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\nX = torch.concat([X0,X1])/255\n\n\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\ny.to(torch.int64).reshape(-1)\n\ntensor([0, 0, 0,  ..., 1, 1, 1])\n\n\n\n# test\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'testing/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'testing/1').ls()])\nXX = torch.concat([X0,X1])/255\n\n\nyy = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\nyy.to(torch.int64).reshape(-1)\n\ntensor([0, 0, 0,  ..., 1, 1, 1])\n\n\n\nds1 = torch.utils.data.TensorDataset(X,y.to(torch.int64).reshape(-1))\nds2 = torch.utils.data.TensorDataset(XX,yy.to(torch.int64).reshape(-1))\n\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=1266) \ndl2 = torch.utils.data.DataLoader(ds2,batch_size=2115) \n\ndls = DataLoaders(dl1,dl2) \n\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten(),\n    torch.nn.Linear(2304,2)\n)\nloss_fn = torch.nn.CrossEntropyLoss() \nlrnr = Learner(dls,net,loss_fn,metrics=[accuracy,error_rate])\n\n\nlrnr.fit(10)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\nerror_rate\ntime\n\n\n\n\n0\n1.128365\n0.601474\n0.463357\n0.536643\n00:00\n\n\n1\n0.684630\n0.304262\n0.975414\n0.024586\n00:00\n\n\n2\n0.503124\n0.144147\n0.989598\n0.010402\n00:00\n\n\n3\n0.373899\n0.068306\n0.996217\n0.003783\n00:00\n\n\n4\n0.281332\n0.040790\n0.996217\n0.003783\n00:00\n\n\n5\n0.215743\n0.026980\n0.996690\n0.003310\n00:00\n\n\n6\n0.168349\n0.019467\n0.996690\n0.003310\n00:00\n\n\n7\n0.133313\n0.014856\n0.998109\n0.001891\n00:00\n\n\n8\n0.106776\n0.011745\n0.998109\n0.001891\n00:00\n\n\n9\n0.086275\n0.009553\n0.999054\n0.000946\n00:00\n\n\n\n\n\ntype 2) y의 형태가 one-hot encoded vector + float일 때 - metrics = accuracy_multi를 사용해야 함 - error_rate는 사용못함\n\ny_onehot = torch.tensor(list(map(lambda x: [1.0,0.0] if x==0 else [0.0,1.0], y)))\nyy_onehot = torch.tensor(list(map(lambda x: [1.0,0.0] if x==0 else [0.0,1.0], yy)))\n\n\ny_onehot = torch.nn.functional.one_hot(y.reshape(-1).to(torch.int64)).to(torch.float32)\nyy_onehot = torch.nn.functional.one_hot(yy.reshape(-1).to(torch.int64)).to(torch.float32)\n\n\ntorch.nn.functional.one_hot() 함수 조건\n\n기본적으로 크기가 n인 벡터가 들어오길 기대\n정수가 들어오는 것을 기대\n\n하지만 원-핫 인코딩을 사용할 때에는 실수형으로 저장 되어야 하므로 마지막에 실수형으로 바꿔줘야 함\n\n\nds1 = torch.utils.data.TensorDataset(X,y_onehot)\nds2 = torch.utils.data.TensorDataset(XX,yy_onehot)\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=1266) \ndl2 = torch.utils.data.DataLoader(ds2,batch_size=2115) \ndls = DataLoaders(dl1,dl2) \n\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten(),\n    torch.nn.Linear(2304,2),\n    #torch.nn.Softmax()\n)\nloss_fn = torch.nn.CrossEntropyLoss() \nlrnr = Learner(dls,net,loss_fn,metrics=[accuracy_multi])\n\n\nlrnr.fit(10)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy_multi\ntime\n\n\n\n\n0\n1.213650\n0.647844\n0.463357\n00:00\n\n\n1\n0.744869\n0.384000\n0.933570\n00:00\n\n\n2\n0.571879\n0.187119\n0.986525\n00:00\n\n\n3\n0.432096\n0.090841\n0.994563\n00:00\n\n\n4\n0.326718\n0.048868\n0.995508\n00:00\n\n\n5\n0.250235\n0.028477\n0.996217\n00:00\n\n\n6\n0.194605\n0.018616\n0.996454\n00:00\n\n\n7\n0.153338\n0.013278\n0.996927\n00:00\n\n\n8\n0.122056\n0.010130\n0.997872\n00:00\n\n\n9\n0.097957\n0.008112\n0.998109\n00:00"
  },
  {
    "objectID": "docs/DL/posts/rstat101.html",
    "href": "docs/DL/posts/rstat101.html",
    "title": "Tutorial",
    "section": "",
    "text": "test12414입니\n123123다"
  },
  {
    "objectID": "docs/DL/rstat_lecture.html",
    "href": "docs/DL/rstat_lecture.html",
    "title": "rstat lecture",
    "section": "",
    "text": "1강\n2강\n3강"
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "JuWon Kwon",
    "section": "",
    "text": "바이오메디컬공학을 전공하고 있는 학부생 입니다.\n초음파와 딥러닝을 공부하고 있습니다."
  }
]