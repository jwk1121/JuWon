<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.340">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="JuWon">
<meta name="dcterms.date" content="2022-02-18">

<title>BME JuWon’s summary - DCGAN paper review</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../../../styles.css">
</head>

<body class="floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="../../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../.././img/minions2.png" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">BME JuWon’s summary</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="true"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../docs/DL/index.html" rel="" target="">
 <span class="menu-text">DL summary</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/jwk1121" rel="" target=""><i class="bi bi-github" role="img" aria-label="JuWon's github">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default toc-left page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">DCGAN paper review</h1>
            <p class="subtitle lead">Deep generative model - DCGAN</p>
                                <div class="quarto-categories">
                <div class="quarto-category">DL</div>
                <div class="quarto-category">Generative model</div>
                <div class="quarto-category">paper review</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>JuWon </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">February 18, 2022</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#dcgan" id="toc-dcgan" class="nav-link active" data-scroll-target="#dcgan">DCGAN</a>
  <ul class="collapse">
  <li><a href="#논문-리뷰" id="toc-논문-리뷰" class="nav-link" data-scroll-target="#논문-리뷰">논문 리뷰</a></li>
  <li><a href="#논문-구현" id="toc-논문-구현" class="nav-link" data-scroll-target="#논문-구현">논문 구현</a>
  <ul class="collapse">
  <li><a href="#모듈-임포트" id="toc-모듈-임포트" class="nav-link" data-scroll-target="#모듈-임포트">모듈 임포트</a></li>
  <li><a href="#g-generator-구현" id="toc-g-generator-구현" class="nav-link" data-scroll-target="#g-generator-구현">G: Generator 구현</a></li>
  <li><a href="#d-discriminator-구현" id="toc-d-discriminator-구현" class="nav-link" data-scroll-target="#d-discriminator-구현">D: Discriminator 구현</a></li>
  <li><a href="#loss-function-정의" id="toc-loss-function-정의" class="nav-link" data-scroll-target="#loss-function-정의">loss function 정의</a></li>
  <li><a href="#데이터-로더-구현" id="toc-데이터-로더-구현" class="nav-link" data-scroll-target="#데이터-로더-구현">데이터 로더 구현</a></li>
  <li><a href="#모델-학습-클래스-정의" id="toc-모델-학습-클래스-정의" class="nav-link" data-scroll-target="#모델-학습-클래스-정의">모델 학습 클래스 정의</a></li>
  <li><a href="#이미지-생성-결과" id="toc-이미지-생성-결과" class="nav-link" data-scroll-target="#이미지-생성-결과">이미지 생성 결과</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="dcgan" class="level1">
<h1>DCGAN</h1>
<section id="논문-리뷰" class="level2">
<h2 class="anchored" data-anchor-id="논문-리뷰">논문 리뷰</h2>
<p>[DCGAN 장점] - 대부분의 상황에서 안정적으로 학습이 됨 - word2vec과 같이 DCGAN으로 학습된 Generator가 벡터 산술 연산이 가능한 성질을 갖음<br>
<img src="img2vec.png" class="img-fluid" alt="Alt text"> - DCGAN이 학습한 필터를 시각화하여 보여줌 -&gt; 특정 필터들이 이미지의 특정 물체를 학습했음을 보여줌<br>
<img src="filter.png" class="img-fluid" alt="Alt text"></p>
<ul>
<li>성능면에서 비지도 학습 알고리즘에 비해 우수함</li>
</ul>
<p>[APPROACH AND MODEL ARCHITECTURE]<br>
DCGAN은<br>
- Max Pooling To Strided Convolution - Fully-Connected Layer 삭제 - BatchNormalization을 추가함 -&gt; deep한 모델이더라도 gradient의 흐름이 잘 전달됨 - ReLU와 Leaky ReLU를 사용</p>
<p>[DETAILS OF ADVERSARIAL TRAINING]</p>
<ul>
<li>모델 및 옵티마이저<br>
<img src="Generator structure.png" class="img-fluid" alt="Alt text">
<ul>
<li><p>mini-batch Stochastic Gradient Descent(SGD) a with batch size of 128</p></li>
<li><p>All weight: zero-centered Normal distribution with std 0.02</p></li>
<li><p>Leaky ReLU: slope 0.2</p></li>
<li><p>Optimizer: Adam (GAN에서는 momentum 사용)</p></li>
<li><p>learning late: 0.0002(0.001은 너무 커서..)</p></li>
<li><p>D’s criterion= <span class="math inline">\(\log(D(x))\)</span><em>(real data</em>) + <span class="math inline">\(\log(1 - D(G(x)))\)</span><em>(fake data)</em></p></li>
<li><p>G’s criterion = <span class="math inline">\(\log(D(G(z)))\)</span></p></li>
</ul></li>
<li>데이터
<ul>
<li>LSUN</li>
<li>FACES</li>
<li>IMAGENET-1K</li>
</ul></li>
</ul>
<p>DCGAN에서 중요한 기준 - NOT MIMICKING TRAIN DATA -&gt; 단순히 학습 데이터를 모방하면 안됨! - “Walking in the latent Space” -&gt; G의 input z의 공간인 latent Space에서 z1에서 z2로 살짝 이동한다 하더라도 급작스러운 변화가 일어나지 않고 물흐르듯 부드러운 변화를 보여줘야 한다.<br>
<img src="vecz2img.png" class="img-fluid" alt="Alt text"></p>
</section>
<section id="논문-구현" class="level2">
<h2 class="anchored" data-anchor-id="논문-구현">논문 구현</h2>
<section id="모듈-임포트" class="level3">
<h3 class="anchored" data-anchor-id="모듈-임포트">모듈 임포트</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.utils.data <span class="im">as</span> data</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.datasets <span class="im">as</span> dsets</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> transforms</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">1234</span>)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">1234</span>)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>random.seed(<span class="dv">1234</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="cnn-사이즈-계산기-정의" class="level4">
<h4 class="anchored" data-anchor-id="cnn-사이즈-계산기-정의">CNN 사이즈 계산기 정의</h4>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> conv_dim(i,k,s,p):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">'''</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co">    nn.Conv2d 사용할 때 사이즈 계산</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co">    i: input image size</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co">    k: kernel size</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co">    s: stride</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co">    p: padding</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co">    '''</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> (i <span class="op">-</span> k <span class="op">+</span> <span class="dv">2</span><span class="op">*</span>p)<span class="op">/</span>s <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> out  </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> convt_dim(i,k,s,p):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">'''</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co">    nn.ConvTranspose2d 사용할 때 사이즈 계산</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co">    i: input image size</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co">    k: kernel size</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co">    s: stride</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co">    p: padding</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co">    '''</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    out <span class="op">=</span> (i<span class="op">-</span><span class="dv">1</span>) <span class="op">*</span> s <span class="op">-</span> <span class="dv">2</span> <span class="op">*</span> p <span class="op">+</span> k</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> out  </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="g-generator-구현" class="level3">
<h3 class="anchored" data-anchor-id="g-generator-구현">G: Generator 구현</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Generator(nn.Module):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, z_dim <span class="op">=</span> <span class="dv">20</span>, image_size <span class="op">=</span> <span class="dv">64</span>):</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(Generator, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>        <span class="co"># layer1 -&gt; W(H) * 4</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layer1 <span class="op">=</span> nn.Sequential(</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>            nn.ConvTranspose2d(z_dim, image_size <span class="op">*</span> <span class="dv">8</span>, kernel_size <span class="op">=</span> <span class="dv">4</span>, stride <span class="op">=</span> <span class="dv">1</span>),</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm2d(image_size <span class="op">*</span> <span class="dv">8</span>),</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># layer2 -&gt; W(H) * 2</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layer2 <span class="op">=</span> nn.Sequential(</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>            nn.ConvTranspose2d(image_size <span class="op">*</span> <span class="dv">8</span>, image_size <span class="op">*</span> <span class="dv">4</span>, kernel_size <span class="op">=</span> <span class="dv">4</span>, stride <span class="op">=</span> <span class="dv">2</span>, padding<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm2d(image_size <span class="op">*</span> <span class="dv">4</span>),</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layer3 <span class="op">=</span> nn.Sequential(</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>            nn.ConvTranspose2d(image_size <span class="op">*</span> <span class="dv">4</span>, image_size <span class="op">*</span> <span class="dv">2</span>, kernel_size <span class="op">=</span> <span class="dv">4</span>, stride <span class="op">=</span> <span class="dv">2</span>, padding<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm2d(image_size <span class="op">*</span> <span class="dv">2</span>),</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layer4 <span class="op">=</span> nn.Sequential(</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>            nn.ConvTranspose2d(image_size <span class="op">*</span> <span class="dv">2</span>, image_size, kernel_size <span class="op">=</span> <span class="dv">4</span>, stride <span class="op">=</span> <span class="dv">2</span>, padding<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm2d(image_size),</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.last <span class="op">=</span> nn.Sequential(</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>            nn.ConvTranspose2d(image_size, <span class="dv">1</span>, kernel_size<span class="op">=</span> <span class="dv">4</span>, stride<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="dv">1</span>), <span class="co"># 흑백 이미지이므로 출력 차원을 1으로 지정한 것</span></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>            nn.Tanh())</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, z):</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.layer1(z)</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.layer2(out)</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.layer3(out)</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.layer4(out)</span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.last(out)</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> out.<span class="bu">type</span>(torch.FloatTensor)</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> out</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="학습이-안된-g의-출력" class="level4">
<h4 class="anchored" data-anchor-id="학습이-안된-g의-출력">학습이 안된 G의 출력</h4>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>G <span class="op">=</span> Generator(z_dim<span class="op">=</span><span class="dv">20</span>, image_size<span class="op">=</span><span class="dv">64</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>input_z <span class="op">=</span> torch.randn(<span class="dv">1</span>, <span class="dv">20</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># tensor size -&gt; (1, 20, 1, 1) </span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co"># pytorch: (batch_size, channel, height, width)</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>input_z <span class="op">=</span> input_z.view(input_z.size(<span class="dv">0</span>), input_z.size(<span class="dv">1</span>), <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>fake_img <span class="op">=</span> G(input_z)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="0c3dff92-78e2-417a-bf3d-05074a3f71e6">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># fake_img[0][0].size() -&gt; (64, 64)</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>img_transformed <span class="op">=</span> fake_img[<span class="dv">0</span>][<span class="dv">0</span>].detach().numpy()</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>plt.imshow(img_transformed, <span class="st">'gray'</span>)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="DCGAN_files/figure-html/cell-7-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
</section>
<section id="d-discriminator-구현" class="level3">
<h3 class="anchored" data-anchor-id="d-discriminator-구현">D: Discriminator 구현</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Discriminator(nn.Module):</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, z_dim<span class="op">=</span><span class="dv">20</span>, image_size<span class="op">=</span><span class="dv">64</span>):</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(Discriminator, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layer1 <span class="op">=</span> nn.Sequential(</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(<span class="dv">1</span>, image_size, kernel_size<span class="op">=</span><span class="dv">4</span>,stride<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>            nn.LeakyReLU(<span class="fl">0.1</span>, inplace<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layer2 <span class="op">=</span> nn.Sequential(</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(image_size, image_size<span class="op">*</span><span class="dv">2</span>, kernel_size<span class="op">=</span><span class="dv">4</span>,stride<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>            nn.LeakyReLU(<span class="fl">0.1</span>, inplace<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layer3 <span class="op">=</span> nn.Sequential(</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(image_size<span class="op">*</span><span class="dv">2</span>, image_size<span class="op">*</span><span class="dv">4</span>, kernel_size<span class="op">=</span><span class="dv">4</span>,stride<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>            nn.LeakyReLU(<span class="fl">0.1</span>, inplace<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.layer4 <span class="op">=</span> nn.Sequential(</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(image_size<span class="op">*</span><span class="dv">4</span>, image_size<span class="op">*</span><span class="dv">8</span>, kernel_size<span class="op">=</span><span class="dv">4</span>,stride<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>            nn.LeakyReLU(<span class="fl">0.1</span>, inplace<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.last <span class="op">=</span> nn.Conv2d(image_size<span class="op">*</span><span class="dv">8</span>, <span class="dv">1</span>, kernel_size<span class="op">=</span><span class="dv">4</span>, stride<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.layer1(x)</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.layer2(out)</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.layer3(out)</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.layer4(out)</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.last(out)</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> out.<span class="bu">type</span>(torch.FloatTensor)</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> out</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="f028a201-9220-4b3a-a6d0-ed89cd0f86e9">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>D <span class="op">=</span> Discriminator(z_dim<span class="op">=</span><span class="dv">20</span>, image_size<span class="op">=</span><span class="dv">64</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>d_out <span class="op">=</span> D(fake_img)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 출력 d_out에 Sigmoid를 곱해 0에서 1로 변환</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(nn.Sigmoid()(d_out))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>tensor([[[[0.4980]]]], grad_fn=&lt;SigmoidBackward0&gt;)</code></pre>
</div>
</div>
</section>
<section id="loss-function-정의" class="level3">
<h3 class="anchored" data-anchor-id="loss-function-정의">loss function 정의</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>mini_batch_size <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 정답 라벨 생성 -&gt; torch.tensor([1,1])</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>label_real <span class="op">=</span> torch.full((mini_batch_size,), <span class="dv">1</span>)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 가짜 라벨 생성 -&gt; torch.tensor([0,0])</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>label_fake <span class="op">=</span> torch.full((mini_batch_size,), <span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 가짜 이미지 생성</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>input_z <span class="op">=</span> torch.randn(mini_batch_size, <span class="dv">20</span>)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="co"># tensor size -&gt; (2,20,1,1)</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>input_z <span class="op">=</span> input_z.view(input_z.size(<span class="dv">0</span>), input_z.size(<span class="dv">1</span>), <span class="dv">1</span>, <span class="dv">1</span>) </span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co"># G에 의해 tensor size -&gt; (2,1,64,64)</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>fake_images <span class="op">=</span> G(input_z)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="co"># D에 의해 tensor size -&gt; (2,1,1,1)</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>d_out_fake <span class="op">=</span> D(fake_images)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="d의-오차함수의-이미지-구현" class="level4">
<h4 class="anchored" data-anchor-id="d의-오차함수의-이미지-구현">D의 오차함수의 이미지 구현</h4>
<p><span class="math inline">\(maximize\)</span> <span class="math inline">\(log(D(x))\)</span>+<span class="math inline">\(log(1 - D(G(z)))\)</span></p>
<div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># loss function 정의</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> nn.BCEWithLogitsLoss(reduction<span class="op">=</span><span class="st">'mean'</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 진짜 이미지 판정</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>d_out_real <span class="op">=</span> D(x)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 가짜 이미지 생성</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>input_z <span class="op">=</span> torch.randn(mini_batch_size, <span class="dv">20</span>)</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>input_z <span class="op">=</span> input_z.view(input_z.size(<span class="dv">0</span>), input_z.size(<span class="dv">1</span>), <span class="dv">1</span>, <span class="dv">1</span>) </span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>fake_images <span class="op">=</span> G(input_z)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>d_out_fake <span class="op">=</span> D(fake_images)</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a><span class="co"># 오차를 계산</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>d_loss_real <span class="op">=</span> loss_fn(d_out_real.view(<span class="op">-</span><span class="dv">1</span>), label_real)</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>d_loss_fake <span class="op">=</span> loss_fn(d_out_fake.view(<span class="op">-</span><span class="dv">1</span>), label_fake)</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>d_loss <span class="op">=</span> d_loss_real <span class="op">+</span> d_loss_fake</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="g의-오차함수의-이미지-구현" class="level4">
<h4 class="anchored" data-anchor-id="g의-오차함수의-이미지-구현">G의 오차함수의 이미지 구현</h4>
<p><span class="math inline">\(maximize\)</span> <span class="math inline">\(log\)</span><span class="math inline">\((D(G(z)))\)</span></p>
<div class="sourceCode" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 가짜 화상을 생성해 판정</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>input_z <span class="op">=</span> torch.randn(mini_batch_size, <span class="dv">20</span>)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>input_z <span class="op">=</span> input_z.view(input_z.size(<span class="dv">0</span>), input_z.size(<span class="dv">1</span>), <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>fake_images <span class="op">=</span> G(input_z)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>d_out_fake <span class="op">=</span> D(fake_images)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 오차를 계산</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>g_loss <span class="op">=</span> criterion(d_out_fake.view(<span class="op">-</span><span class="dv">1</span>), label_real)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="데이터-로더-구현" class="level3">
<h3 class="anchored" data-anchor-id="데이터-로더-구현">데이터 로더 구현</h3>
<section id="데이터-준비" class="level4">
<h4 class="anchored" data-anchor-id="데이터-준비">데이터 준비</h4>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> urllib.request</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> zipfile</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tarfile</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_openml</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>mnist_F <span class="op">=</span> fetch_openml(<span class="st">'mnist_784'</span>, version<span class="op">=</span><span class="dv">1</span>, data_home<span class="op">=</span><span class="st">"./data/"</span>)  </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="mnist-손글씨-데이터" class="level5">
<h5 class="anchored" data-anchor-id="mnist-손글씨-데이터">mnist 손글씨 데이터</h5>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_openml</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>mnist <span class="op">=</span> fetch_openml(<span class="st">'mnist_784'</span>, version<span class="op">=</span><span class="dv">1</span>, data_home<span class="op">=</span><span class="st">"./data/"</span>)  </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> mnist.data.to_numpy()</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> mnist.target.to_numpy()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>data_dir_path <span class="op">=</span> <span class="st">"./data/img_78/"</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> os.path.exists(data_dir_path):</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    os.mkdir(data_dir_path)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="161a96d6-72d3-4684-a159-443fe5f47629">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># MNIST에서 숫자7, 8의 화상만 "img_78" 폴더에 화상으로 저장해 나간다</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>count7<span class="op">=</span><span class="dv">0</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>count8<span class="op">=</span><span class="dv">0</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>max_num<span class="op">=</span><span class="dv">200</span>  <span class="co"># 화상은 200장씩 작성한다</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(X)):</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 화상7 작성</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (y[i] <span class="kw">is</span> <span class="st">"7"</span>) <span class="kw">and</span> (count7<span class="op">&lt;</span>max_num):</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>        file_path<span class="op">=</span><span class="st">"./data/img_78/img_7_"</span><span class="op">+</span><span class="bu">str</span>(count7)<span class="op">+</span><span class="st">".jpg"</span></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>        im_f<span class="op">=</span>(X[i].reshape(<span class="dv">28</span>, <span class="dv">28</span>))  <span class="co"># 화상을 28×28의 형태로 변경</span></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>        pil_img_f <span class="op">=</span> Image.fromarray(im_f.astype(np.uint8))  <span class="co"># 화상을 PIL으로</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>        pil_img_f <span class="op">=</span> pil_img_f.resize((<span class="dv">64</span>, <span class="dv">64</span>), Image.BICUBIC)  <span class="co"># 64×64로 확대</span></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>        pil_img_f.save(file_path)  <span class="co"># 저장</span></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>        count7<span class="op">+=</span><span class="dv">1</span> </span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 화상8 작성</span></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (y[i] <span class="kw">is</span> <span class="st">"8"</span>) <span class="kw">and</span> (count8<span class="op">&lt;</span>max_num):</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>        file_path<span class="op">=</span><span class="st">"./data/img_78/img_8_"</span><span class="op">+</span><span class="bu">str</span>(count8)<span class="op">+</span><span class="st">".jpg"</span></span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>        im_f<span class="op">=</span>(X[i].reshape(<span class="dv">28</span>, <span class="dv">28</span>))  <span class="co"># 화상을 28×28의 형태로 변경</span></span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>        pil_img_f <span class="op">=</span> Image.fromarray(im_f.astype(np.uint8))  <span class="co"># 화상을 PIL으로</span></span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>        pil_img_f <span class="op">=</span> pil_img_f.resize((<span class="dv">64</span>, <span class="dv">64</span>), Image.BICUBIC)  <span class="co"># 64×64로 확대</span></span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>        pil_img_f.save(file_path)  <span class="co"># 저장</span></span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>        count8<span class="op">+=</span><span class="dv">1</span> </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>&lt;&gt;:9: SyntaxWarning: "is" with a literal. Did you mean "=="?
&lt;&gt;:18: SyntaxWarning: "is" with a literal. Did you mean "=="?
&lt;&gt;:9: SyntaxWarning: "is" with a literal. Did you mean "=="?
&lt;&gt;:18: SyntaxWarning: "is" with a literal. Did you mean "=="?
C:\Users\default.DESKTOP-HUJV032\AppData\Local\Temp\ipykernel_12224\1822497188.py:9: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if (y[i] is "7") and (count7&lt;max_num):
C:\Users\default.DESKTOP-HUJV032\AppData\Local\Temp\ipykernel_12224\1822497188.py:18: SyntaxWarning: "is" with a literal. Did you mean "=="?
  if (y[i] is "8") and (count8&lt;max_num):
C:\Users\default.DESKTOP-HUJV032\AppData\Local\Temp\ipykernel_12224\1822497188.py:13: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.
  pil_img_f = pil_img_f.resize((64, 64), Image.BICUBIC)  # 64×64로 확대
C:\Users\default.DESKTOP-HUJV032\AppData\Local\Temp\ipykernel_12224\1822497188.py:22: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.
  pil_img_f = pil_img_f.resize((64, 64), Image.BICUBIC)  # 64×64로 확대</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> make_datapath_list():</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>    train_img_list <span class="op">=</span> <span class="bu">list</span>() </span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> img_idx <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">200</span>):</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>        img_path <span class="op">=</span> <span class="st">"./data/img_78/img_7_"</span> <span class="op">+</span> <span class="bu">str</span>(img_idx)<span class="op">+</span><span class="st">'.jpg'</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>        train_img_list.append(img_path)</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>        img_path <span class="op">=</span> <span class="st">"./data/img_78/img_8_"</span> <span class="op">+</span> <span class="bu">str</span>(img_idx)<span class="op">+</span><span class="st">'.jpg'</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>        train_img_list.append(img_path)</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> train_img_list</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="데이터-가공-클래스-정의" class="level4">
<h4 class="anchored" data-anchor-id="데이터-가공-클래스-정의">데이터 가공 클래스 정의</h4>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ImageTransform():</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""이미지 전처리 클래스"""</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, mean, std):</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.data_transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>            transforms.ToTensor(),</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>            transforms.Normalize(mean, std)</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, img):</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.data_transform(img)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> GAN_Img_Dataset(data.Dataset):</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Dataset 클래스. PyTorch의 Dataset 클래스를 상속"""</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, file_list, transform):</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.file_list <span class="op">=</span> file_list</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.transform <span class="op">=</span> transform</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>        <span class="co">'''이미지 개수 반환'''</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.file_list)</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, index):</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>        <span class="co">'''전처리된 이미지를 Tensor 형식 데이터로 변환'''</span></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>        img_path <span class="op">=</span> <span class="va">self</span>.file_list[index]</span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>        img <span class="op">=</span> Image.<span class="bu">open</span>(img_path)  <span class="co"># [높이][폭]흑백</span></span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 이미지 전처리</span></span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a>        img_transformed <span class="op">=</span> <span class="va">self</span>.transform(img)</span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a>        img_transformed <span class="op">=</span> img_transformed.<span class="bu">type</span>(torch.FloatTensor)</span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> img_transformed</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="0764697f-0ce7-4d22-debf-05c57ca0fb34">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DataLoader 작성과 동작 확인</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 파일 리스트를 작성</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>train_img_list<span class="op">=</span>make_datapath_list()</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Dataset 작성</span></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>mean <span class="op">=</span> (<span class="fl">0.5</span>,)</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>std <span class="op">=</span> (<span class="fl">0.5</span>,)</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> GAN_Img_Dataset(file_list<span class="op">=</span>train_img_list, transform<span class="op">=</span>ImageTransform(mean, std))</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a><span class="co"># DataLoader 작성</span></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>train_dataloader <span class="op">=</span> torch.utils.data.DataLoader(</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>    train_dataset, batch_size<span class="op">=</span>batch_size, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a><span class="co"># 동작 확인</span></span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>batch_iterator <span class="op">=</span> <span class="bu">iter</span>(train_dataloader)  <span class="co"># 반복자로 변환</span></span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>imges <span class="op">=</span> <span class="bu">next</span>(batch_iterator)  <span class="co"># 1번째 요소를 꺼낸다</span></span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(imges.size())  <span class="co"># torch.Size([64, 1, 64, 64])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>torch.Size([64, 1, 64, 64])</code></pre>
</div>
</div>
</section>
</section>
<section id="모델-학습-클래스-정의" class="level3">
<h3 class="anchored" data-anchor-id="모델-학습-클래스-정의">모델 학습 클래스 정의</h3>
<div class="cell" data-outputid="5c6cc610-bd6c-420a-965b-5969efdd43cb">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 네트워크 초기화</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> weights_init(m):</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>    classname <span class="op">=</span> m.__class__.<span class="va">__name__</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> classname.find(<span class="st">'Conv'</span>) <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span>:</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Conv2dとConvTranspose2d 초기화</span></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>        nn.init.normal_(m.weight.data, <span class="fl">0.0</span>, <span class="fl">0.02</span>)</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>        nn.init.constant_(m.bias.data, <span class="dv">0</span>)</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> classname.find(<span class="st">'BatchNorm'</span>) <span class="op">!=</span> <span class="op">-</span><span class="dv">1</span>:</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># BatchNorm2d 초기화</span></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>        nn.init.normal_(m.weight.data, <span class="fl">1.0</span>, <span class="fl">0.02</span>)</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>        nn.init.constant_(m.bias.data, <span class="dv">0</span>)</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a><span class="co"># 초기화 실시</span></span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>G.<span class="bu">apply</span>(weights_init)</span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>D.<span class="bu">apply</span>(weights_init)</span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"네트워크 초기화 완료"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>네트워크 초기화 완료</code></pre>
</div>
</div>
<div class="cell" data-outputid="cc862000-c096-4471-d080-d9f27cec1195">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">"cuda:0"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>)<span class="op">;</span>device</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>device(type='cuda', index=0)</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 모델을 학습시키는 함수를 작성</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_model(G, D, dataloader, num_epochs):</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># GPU가 사용 가능한지 확인</span></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> torch.device(<span class="st">"cuda:0"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>)</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"사용 장치: "</span>, device)</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 최적화 기법 설정</span></span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>    g_lr, d_lr <span class="op">=</span> <span class="fl">0.0001</span>, <span class="fl">0.0004</span></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>    beta1, beta2 <span class="op">=</span> <span class="fl">0.0</span>, <span class="fl">0.9</span></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>    g_optimizer <span class="op">=</span> torch.optim.Adam(G.parameters(), g_lr, [beta1, beta2])</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>    d_optimizer <span class="op">=</span> torch.optim.Adam(D.parameters(), d_lr, [beta1, beta2])</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 오차함수 정의</span></span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>    criterion <span class="op">=</span> nn.BCEWithLogitsLoss(reduction<span class="op">=</span><span class="st">'mean'</span>)</span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 파라미터를 하드코딩</span></span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>    z_dim <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>    mini_batch_size <span class="op">=</span> <span class="dv">64</span></span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 네트워크를 GPU로</span></span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a>    G.to(device)</span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a>    D.to(device)</span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-25"><a href="#cb30-25" aria-hidden="true" tabindex="-1"></a>    G.train()  <span class="co"># 모델을 훈련 모드로</span></span>
<span id="cb30-26"><a href="#cb30-26" aria-hidden="true" tabindex="-1"></a>    D.train()  <span class="co"># 모델을 훈련 모드로</span></span>
<span id="cb30-27"><a href="#cb30-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-28"><a href="#cb30-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 네트워크가 어느 정도 고정되면, 고속화시킨다</span></span>
<span id="cb30-29"><a href="#cb30-29" aria-hidden="true" tabindex="-1"></a>    torch.backends.cudnn.benchmark <span class="op">=</span> <span class="va">True</span></span>
<span id="cb30-30"><a href="#cb30-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-31"><a href="#cb30-31" aria-hidden="true" tabindex="-1"></a>    num_train_imgs <span class="op">=</span> <span class="bu">len</span>(dataloader.dataset)</span>
<span id="cb30-32"><a href="#cb30-32" aria-hidden="true" tabindex="-1"></a>    batch_size <span class="op">=</span> dataloader.batch_size</span>
<span id="cb30-33"><a href="#cb30-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-34"><a href="#cb30-34" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 반복 카운터 설정</span></span>
<span id="cb30-35"><a href="#cb30-35" aria-hidden="true" tabindex="-1"></a>    iteration <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb30-36"><a href="#cb30-36" aria-hidden="true" tabindex="-1"></a>    logs <span class="op">=</span> []</span>
<span id="cb30-37"><a href="#cb30-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-38"><a href="#cb30-38" aria-hidden="true" tabindex="-1"></a>    <span class="co"># epoch 루프</span></span>
<span id="cb30-39"><a href="#cb30-39" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb30-40"><a href="#cb30-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-41"><a href="#cb30-41" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 개시 시간을 저장</span></span>
<span id="cb30-42"><a href="#cb30-42" aria-hidden="true" tabindex="-1"></a>        t_epoch_start <span class="op">=</span> time.time()</span>
<span id="cb30-43"><a href="#cb30-43" aria-hidden="true" tabindex="-1"></a>        epoch_g_loss <span class="op">=</span> <span class="fl">0.0</span>  <span class="co"># epoch의 손실합</span></span>
<span id="cb30-44"><a href="#cb30-44" aria-hidden="true" tabindex="-1"></a>        epoch_d_loss <span class="op">=</span> <span class="fl">0.0</span>  <span class="co"># epoch의 손실합</span></span>
<span id="cb30-45"><a href="#cb30-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-46"><a href="#cb30-46" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'-------------'</span>)</span>
<span id="cb30-47"><a href="#cb30-47" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'Epoch </span><span class="sc">{}</span><span class="st">/</span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(epoch, num_epochs))</span>
<span id="cb30-48"><a href="#cb30-48" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'-------------'</span>)</span>
<span id="cb30-49"><a href="#cb30-49" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'(train)'</span>)</span>
<span id="cb30-50"><a href="#cb30-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-51"><a href="#cb30-51" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 데이터 로더에서 minibatch씩 꺼내는 루프</span></span>
<span id="cb30-52"><a href="#cb30-52" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> imges <span class="kw">in</span> dataloader:</span>
<span id="cb30-53"><a href="#cb30-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-54"><a href="#cb30-54" aria-hidden="true" tabindex="-1"></a>            <span class="co"># --------------------</span></span>
<span id="cb30-55"><a href="#cb30-55" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 1. Discriminator 학습</span></span>
<span id="cb30-56"><a href="#cb30-56" aria-hidden="true" tabindex="-1"></a>            <span class="co"># --------------------</span></span>
<span id="cb30-57"><a href="#cb30-57" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 미니 배치 크기가 1이면, 배치 노멀라이제이션에서 에러가 발생하므로 피한다</span></span>
<span id="cb30-58"><a href="#cb30-58" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> imges.size()[<span class="dv">0</span>] <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb30-59"><a href="#cb30-59" aria-hidden="true" tabindex="-1"></a>                <span class="cf">continue</span></span>
<span id="cb30-60"><a href="#cb30-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-61"><a href="#cb30-61" aria-hidden="true" tabindex="-1"></a>            <span class="co"># GPU가 사용 가능하면 GPU로 데이터를 보낸다</span></span>
<span id="cb30-62"><a href="#cb30-62" aria-hidden="true" tabindex="-1"></a>            imges <span class="op">=</span> imges.to(device)</span>
<span id="cb30-63"><a href="#cb30-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-64"><a href="#cb30-64" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 정답 라벨과 가짜 라벨 작성</span></span>
<span id="cb30-65"><a href="#cb30-65" aria-hidden="true" tabindex="-1"></a>            <span class="co"># epoch의 마지막 반복은 미니 배치 수가 줄어든다</span></span>
<span id="cb30-66"><a href="#cb30-66" aria-hidden="true" tabindex="-1"></a>            mini_batch_size <span class="op">=</span> imges.size()[<span class="dv">0</span>]</span>
<span id="cb30-67"><a href="#cb30-67" aria-hidden="true" tabindex="-1"></a>            label_real <span class="op">=</span> torch.full((mini_batch_size,), <span class="dv">1</span>).to(device)</span>
<span id="cb30-68"><a href="#cb30-68" aria-hidden="true" tabindex="-1"></a>            label_fake <span class="op">=</span> torch.full((mini_batch_size,), <span class="dv">0</span>).to(device)</span>
<span id="cb30-69"><a href="#cb30-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-70"><a href="#cb30-70" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 진짜 이미지 판정</span></span>
<span id="cb30-71"><a href="#cb30-71" aria-hidden="true" tabindex="-1"></a>            d_out_real <span class="op">=</span> D(imges)</span>
<span id="cb30-72"><a href="#cb30-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-73"><a href="#cb30-73" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 가짜 이미지 생성해 판정</span></span>
<span id="cb30-74"><a href="#cb30-74" aria-hidden="true" tabindex="-1"></a>            input_z <span class="op">=</span> torch.randn(mini_batch_size, z_dim).to(device)</span>
<span id="cb30-75"><a href="#cb30-75" aria-hidden="true" tabindex="-1"></a>            input_z <span class="op">=</span> input_z.view(input_z.size(<span class="dv">0</span>), input_z.size(<span class="dv">1</span>), <span class="dv">1</span>, <span class="dv">1</span>).to(device)</span>
<span id="cb30-76"><a href="#cb30-76" aria-hidden="true" tabindex="-1"></a>            fake_images <span class="op">=</span> G(input_z)</span>
<span id="cb30-77"><a href="#cb30-77" aria-hidden="true" tabindex="-1"></a>            d_out_fake <span class="op">=</span> D(fake_images.to(device))</span>
<span id="cb30-78"><a href="#cb30-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-79"><a href="#cb30-79" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 오차를 계산</span></span>
<span id="cb30-80"><a href="#cb30-80" aria-hidden="true" tabindex="-1"></a>            d_loss_real <span class="op">=</span> criterion(d_out_real.view(<span class="op">-</span><span class="dv">1</span>).to(device), label_real.<span class="bu">float</span>())</span>
<span id="cb30-81"><a href="#cb30-81" aria-hidden="true" tabindex="-1"></a>            d_loss_fake <span class="op">=</span> criterion(d_out_fake.view(<span class="op">-</span><span class="dv">1</span>).to(device), label_fake.<span class="bu">float</span>())</span>
<span id="cb30-82"><a href="#cb30-82" aria-hidden="true" tabindex="-1"></a>            d_loss <span class="op">=</span> d_loss_real <span class="op">+</span> d_loss_fake</span>
<span id="cb30-83"><a href="#cb30-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-84"><a href="#cb30-84" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 역전파</span></span>
<span id="cb30-85"><a href="#cb30-85" aria-hidden="true" tabindex="-1"></a>            g_optimizer.zero_grad()</span>
<span id="cb30-86"><a href="#cb30-86" aria-hidden="true" tabindex="-1"></a>            d_optimizer.zero_grad()</span>
<span id="cb30-87"><a href="#cb30-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-88"><a href="#cb30-88" aria-hidden="true" tabindex="-1"></a>            d_loss.backward()</span>
<span id="cb30-89"><a href="#cb30-89" aria-hidden="true" tabindex="-1"></a>            d_optimizer.step()</span>
<span id="cb30-90"><a href="#cb30-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-91"><a href="#cb30-91" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 2. Generator 학습</span></span>
<span id="cb30-92"><a href="#cb30-92" aria-hidden="true" tabindex="-1"></a>            <span class="co"># --------------------</span></span>
<span id="cb30-93"><a href="#cb30-93" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 가짜 이미지 생성해 판정</span></span>
<span id="cb30-94"><a href="#cb30-94" aria-hidden="true" tabindex="-1"></a>            input_z <span class="op">=</span> torch.randn(mini_batch_size, z_dim).to(device)</span>
<span id="cb30-95"><a href="#cb30-95" aria-hidden="true" tabindex="-1"></a>            input_z <span class="op">=</span> input_z.view(input_z.size(<span class="dv">0</span>), input_z.size(<span class="dv">1</span>), <span class="dv">1</span>, <span class="dv">1</span>).to(device)</span>
<span id="cb30-96"><a href="#cb30-96" aria-hidden="true" tabindex="-1"></a>            fake_images <span class="op">=</span> G(input_z)</span>
<span id="cb30-97"><a href="#cb30-97" aria-hidden="true" tabindex="-1"></a>            d_out_fake <span class="op">=</span> D(fake_images.to(device))</span>
<span id="cb30-98"><a href="#cb30-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-99"><a href="#cb30-99" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 오차를 계산</span></span>
<span id="cb30-100"><a href="#cb30-100" aria-hidden="true" tabindex="-1"></a>            g_loss <span class="op">=</span> criterion(d_out_fake.view(<span class="op">-</span><span class="dv">1</span>).to(device), label_real.<span class="bu">float</span>().to(device))</span>
<span id="cb30-101"><a href="#cb30-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-102"><a href="#cb30-102" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 역전파</span></span>
<span id="cb30-103"><a href="#cb30-103" aria-hidden="true" tabindex="-1"></a>            g_optimizer.zero_grad()</span>
<span id="cb30-104"><a href="#cb30-104" aria-hidden="true" tabindex="-1"></a>            d_optimizer.zero_grad()</span>
<span id="cb30-105"><a href="#cb30-105" aria-hidden="true" tabindex="-1"></a>            g_loss.backward()</span>
<span id="cb30-106"><a href="#cb30-106" aria-hidden="true" tabindex="-1"></a>            g_optimizer.step()</span>
<span id="cb30-107"><a href="#cb30-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-108"><a href="#cb30-108" aria-hidden="true" tabindex="-1"></a>            <span class="co"># --------------------</span></span>
<span id="cb30-109"><a href="#cb30-109" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 3. 기록</span></span>
<span id="cb30-110"><a href="#cb30-110" aria-hidden="true" tabindex="-1"></a>            <span class="co"># --------------------</span></span>
<span id="cb30-111"><a href="#cb30-111" aria-hidden="true" tabindex="-1"></a>            epoch_d_loss <span class="op">+=</span> d_loss.item()</span>
<span id="cb30-112"><a href="#cb30-112" aria-hidden="true" tabindex="-1"></a>            epoch_g_loss <span class="op">+=</span> g_loss.item()</span>
<span id="cb30-113"><a href="#cb30-113" aria-hidden="true" tabindex="-1"></a>            iteration <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb30-114"><a href="#cb30-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-115"><a href="#cb30-115" aria-hidden="true" tabindex="-1"></a>        <span class="co"># epoch의 phase별 loss와 정답률</span></span>
<span id="cb30-116"><a href="#cb30-116" aria-hidden="true" tabindex="-1"></a>        t_epoch_finish <span class="op">=</span> time.time()</span>
<span id="cb30-117"><a href="#cb30-117" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'-------------'</span>)</span>
<span id="cb30-118"><a href="#cb30-118" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'epoch </span><span class="sc">{}</span><span class="st"> || Epoch_D_Loss:</span><span class="sc">{:.4f}</span><span class="st"> ||Epoch_G_Loss:</span><span class="sc">{:.4f}</span><span class="st">'</span>.<span class="bu">format</span>(</span>
<span id="cb30-119"><a href="#cb30-119" aria-hidden="true" tabindex="-1"></a>            epoch, epoch_d_loss<span class="op">/</span>batch_size, epoch_g_loss<span class="op">/</span>batch_size))</span>
<span id="cb30-120"><a href="#cb30-120" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'timer:  </span><span class="sc">{:.4f}</span><span class="st"> sec.'</span>.<span class="bu">format</span>(t_epoch_finish <span class="op">-</span> t_epoch_start))</span>
<span id="cb30-121"><a href="#cb30-121" aria-hidden="true" tabindex="-1"></a>        t_epoch_start <span class="op">=</span> time.time()</span>
<span id="cb30-122"><a href="#cb30-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-123"><a href="#cb30-123" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> G, D</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-outputid="45c9c759-b0aa-40f5-a525-57569f0aca12">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>num_epochs <span class="op">=</span> <span class="dv">200</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>G_update, D_update <span class="op">=</span> train_model(G, D, dataloader<span class="op">=</span>train_dataloader, num_epochs<span class="op">=</span>num_epochs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>사용 장치:  cuda:0
-------------
Epoch 0/200
-------------
(train)
-------------
epoch 0 || Epoch_D_Loss:0.0147 ||Epoch_G_Loss:0.7212
timer:  0.9429 sec.
-------------
Epoch 1/200
-------------
(train)
-------------
epoch 1 || Epoch_D_Loss:0.0108 ||Epoch_G_Loss:0.8667
timer:  0.7360 sec.
-------------
Epoch 2/200
-------------
(train)
-------------
epoch 2 || Epoch_D_Loss:0.0266 ||Epoch_G_Loss:0.6338
timer:  0.7420 sec.
-------------
Epoch 3/200
-------------
(train)
-------------
epoch 3 || Epoch_D_Loss:0.0029 ||Epoch_G_Loss:0.7435
timer:  0.7325 sec.
-------------
Epoch 4/200
-------------
(train)
-------------
epoch 4 || Epoch_D_Loss:0.0038 ||Epoch_G_Loss:0.7857
timer:  0.7349 sec.
-------------
Epoch 5/200
-------------
(train)
-------------
epoch 5 || Epoch_D_Loss:0.0128 ||Epoch_G_Loss:0.7397
timer:  0.7323 sec.
-------------
Epoch 6/200
-------------
(train)
-------------
epoch 6 || Epoch_D_Loss:0.0058 ||Epoch_G_Loss:0.9182
timer:  0.7353 sec.
-------------
Epoch 7/200
-------------
(train)
-------------
epoch 7 || Epoch_D_Loss:0.0561 ||Epoch_G_Loss:0.6317
timer:  0.7301 sec.
-------------
Epoch 8/200
-------------
(train)
-------------
epoch 8 || Epoch_D_Loss:0.0046 ||Epoch_G_Loss:0.7038
timer:  0.7350 sec.
-------------
Epoch 9/200
-------------
(train)
-------------
epoch 9 || Epoch_D_Loss:0.0024 ||Epoch_G_Loss:0.7608
timer:  0.7320 sec.
-------------
Epoch 10/200
-------------
(train)
-------------
epoch 10 || Epoch_D_Loss:0.0025 ||Epoch_G_Loss:0.7988
timer:  0.7388 sec.
-------------
Epoch 11/200
-------------
(train)
-------------
epoch 11 || Epoch_D_Loss:0.0035 ||Epoch_G_Loss:0.8410
timer:  0.7402 sec.
-------------
Epoch 12/200
-------------
(train)
-------------
epoch 12 || Epoch_D_Loss:0.0554 ||Epoch_G_Loss:0.9072
timer:  0.7309 sec.
-------------
Epoch 13/200
-------------
(train)
-------------
epoch 13 || Epoch_D_Loss:0.0054 ||Epoch_G_Loss:0.6871
timer:  0.7408 sec.
-------------
Epoch 14/200
-------------
(train)
-------------
epoch 14 || Epoch_D_Loss:0.0027 ||Epoch_G_Loss:0.8104
timer:  0.7420 sec.
-------------
Epoch 15/200
-------------
(train)
-------------
epoch 15 || Epoch_D_Loss:0.0017 ||Epoch_G_Loss:0.8349
timer:  0.7335 sec.
-------------
Epoch 16/200
-------------
(train)
-------------
epoch 16 || Epoch_D_Loss:0.0009 ||Epoch_G_Loss:0.8269
timer:  0.7387 sec.
-------------
Epoch 17/200
-------------
(train)
-------------
epoch 17 || Epoch_D_Loss:0.0113 ||Epoch_G_Loss:0.9406
timer:  0.7346 sec.
-------------
Epoch 18/200
-------------
(train)
-------------
epoch 18 || Epoch_D_Loss:0.0484 ||Epoch_G_Loss:0.7943
timer:  0.7341 sec.
-------------
Epoch 19/200
-------------
(train)
-------------
epoch 19 || Epoch_D_Loss:0.0038 ||Epoch_G_Loss:0.7086
timer:  0.7367 sec.
-------------
Epoch 20/200
-------------
(train)
-------------
epoch 20 || Epoch_D_Loss:0.0026 ||Epoch_G_Loss:0.8174
timer:  0.7461 sec.
-------------
Epoch 21/200
-------------
(train)
-------------
epoch 21 || Epoch_D_Loss:0.0023 ||Epoch_G_Loss:0.9420
timer:  0.7323 sec.
-------------
Epoch 22/200
-------------
(train)
-------------
epoch 22 || Epoch_D_Loss:0.0253 ||Epoch_G_Loss:0.7721
timer:  0.7278 sec.
-------------
Epoch 23/200
-------------
(train)
-------------
epoch 23 || Epoch_D_Loss:0.0093 ||Epoch_G_Loss:0.7429
timer:  0.7256 sec.
-------------
Epoch 24/200
-------------
(train)
-------------
epoch 24 || Epoch_D_Loss:0.0123 ||Epoch_G_Loss:0.8130
timer:  0.7300 sec.
-------------
Epoch 25/200
-------------
(train)
-------------
epoch 25 || Epoch_D_Loss:0.0103 ||Epoch_G_Loss:0.8479
timer:  0.7365 sec.
-------------
Epoch 26/200
-------------
(train)
-------------
epoch 26 || Epoch_D_Loss:0.0015 ||Epoch_G_Loss:0.8154
timer:  0.7331 sec.
-------------
Epoch 27/200
-------------
(train)
-------------
epoch 27 || Epoch_D_Loss:0.0012 ||Epoch_G_Loss:0.8887
timer:  0.7366 sec.
-------------
Epoch 28/200
-------------
(train)
-------------
epoch 28 || Epoch_D_Loss:0.0017 ||Epoch_G_Loss:1.0104
timer:  0.7301 sec.
-------------
Epoch 29/200
-------------
(train)
-------------
epoch 29 || Epoch_D_Loss:0.0665 ||Epoch_G_Loss:0.6415
timer:  0.7291 sec.
-------------
Epoch 30/200
-------------
(train)
-------------
epoch 30 || Epoch_D_Loss:0.0060 ||Epoch_G_Loss:0.7702
timer:  0.7330 sec.
-------------
Epoch 31/200
-------------
(train)
-------------
epoch 31 || Epoch_D_Loss:0.0018 ||Epoch_G_Loss:0.8099
timer:  0.7369 sec.
-------------
Epoch 32/200
-------------
(train)
-------------
epoch 32 || Epoch_D_Loss:0.0012 ||Epoch_G_Loss:0.8387
timer:  0.7320 sec.
-------------
Epoch 33/200
-------------
(train)
-------------
epoch 33 || Epoch_D_Loss:0.0116 ||Epoch_G_Loss:0.9780
timer:  0.7371 sec.
-------------
Epoch 34/200
-------------
(train)
-------------
epoch 34 || Epoch_D_Loss:0.0895 ||Epoch_G_Loss:0.6259
timer:  0.7390 sec.
-------------
Epoch 35/200
-------------
(train)
-------------
epoch 35 || Epoch_D_Loss:0.0040 ||Epoch_G_Loss:0.7130
timer:  0.7300 sec.
-------------
Epoch 36/200
-------------
(train)
-------------
epoch 36 || Epoch_D_Loss:0.0033 ||Epoch_G_Loss:0.7479
timer:  0.7291 sec.
-------------
Epoch 37/200
-------------
(train)
-------------
epoch 37 || Epoch_D_Loss:0.0019 ||Epoch_G_Loss:0.7853
timer:  0.7266 sec.
-------------
Epoch 38/200
-------------
(train)
-------------
epoch 38 || Epoch_D_Loss:0.0034 ||Epoch_G_Loss:0.7967
timer:  0.7288 sec.
-------------
Epoch 39/200
-------------
(train)
-------------
epoch 39 || Epoch_D_Loss:0.0376 ||Epoch_G_Loss:0.9572
timer:  0.7312 sec.
-------------
Epoch 40/200
-------------
(train)
-------------
epoch 40 || Epoch_D_Loss:0.0112 ||Epoch_G_Loss:0.7412
timer:  0.7272 sec.
-------------
Epoch 41/200
-------------
(train)
-------------
epoch 41 || Epoch_D_Loss:0.0022 ||Epoch_G_Loss:0.8254
timer:  0.7251 sec.
-------------
Epoch 42/200
-------------
(train)
-------------
epoch 42 || Epoch_D_Loss:0.0017 ||Epoch_G_Loss:0.8413
timer:  0.7251 sec.
-------------
Epoch 43/200
-------------
(train)
-------------
epoch 43 || Epoch_D_Loss:0.0007 ||Epoch_G_Loss:0.8888
timer:  0.7370 sec.
-------------
Epoch 44/200
-------------
(train)
-------------
epoch 44 || Epoch_D_Loss:0.0010 ||Epoch_G_Loss:0.9397
timer:  0.7321 sec.
-------------
Epoch 45/200
-------------
(train)
-------------
epoch 45 || Epoch_D_Loss:0.0589 ||Epoch_G_Loss:0.7371
timer:  0.7245 sec.
-------------
Epoch 46/200
-------------
(train)
-------------
epoch 46 || Epoch_D_Loss:0.0032 ||Epoch_G_Loss:0.7395
timer:  0.7276 sec.
-------------
Epoch 47/200
-------------
(train)
-------------
epoch 47 || Epoch_D_Loss:0.0037 ||Epoch_G_Loss:0.8705
timer:  0.7277 sec.
-------------
Epoch 48/200
-------------
(train)
-------------
epoch 48 || Epoch_D_Loss:0.0013 ||Epoch_G_Loss:0.8553
timer:  0.7288 sec.
-------------
Epoch 49/200
-------------
(train)
-------------
epoch 49 || Epoch_D_Loss:0.0024 ||Epoch_G_Loss:0.8959
timer:  0.7374 sec.
-------------
Epoch 50/200
-------------
(train)
-------------
epoch 50 || Epoch_D_Loss:0.0429 ||Epoch_G_Loss:0.9181
timer:  0.7258 sec.
-------------
Epoch 51/200
-------------
(train)
-------------
epoch 51 || Epoch_D_Loss:0.0030 ||Epoch_G_Loss:0.7838
timer:  0.7300 sec.
-------------
Epoch 52/200
-------------
(train)
-------------
epoch 52 || Epoch_D_Loss:0.0032 ||Epoch_G_Loss:0.8647
timer:  0.7330 sec.
-------------
Epoch 53/200
-------------
(train)
-------------
epoch 53 || Epoch_D_Loss:0.0010 ||Epoch_G_Loss:0.8791
timer:  0.7306 sec.
-------------
Epoch 54/200
-------------
(train)
-------------
epoch 54 || Epoch_D_Loss:0.0362 ||Epoch_G_Loss:0.9293
timer:  0.7291 sec.
-------------
Epoch 55/200
-------------
(train)
-------------
epoch 55 || Epoch_D_Loss:0.0123 ||Epoch_G_Loss:0.7459
timer:  0.7313 sec.
-------------
Epoch 56/200
-------------
(train)
-------------
epoch 56 || Epoch_D_Loss:0.0033 ||Epoch_G_Loss:0.8016
timer:  0.7408 sec.
-------------
Epoch 57/200
-------------
(train)
-------------
epoch 57 || Epoch_D_Loss:0.0026 ||Epoch_G_Loss:0.8647
timer:  0.7294 sec.
-------------
Epoch 58/200
-------------
(train)
-------------
epoch 58 || Epoch_D_Loss:0.0026 ||Epoch_G_Loss:0.8626
timer:  0.7275 sec.
-------------
Epoch 59/200
-------------
(train)
-------------
epoch 59 || Epoch_D_Loss:0.0625 ||Epoch_G_Loss:0.9511
timer:  0.7284 sec.
-------------
Epoch 60/200
-------------
(train)
-------------
epoch 60 || Epoch_D_Loss:0.0097 ||Epoch_G_Loss:0.7070
timer:  0.7263 sec.
-------------
Epoch 61/200
-------------
(train)
-------------
epoch 61 || Epoch_D_Loss:0.0028 ||Epoch_G_Loss:0.7738
timer:  0.7272 sec.
-------------
Epoch 62/200
-------------
(train)
-------------
epoch 62 || Epoch_D_Loss:0.0016 ||Epoch_G_Loss:0.7819
timer:  0.7280 sec.
-------------
Epoch 63/200
-------------
(train)
-------------
epoch 63 || Epoch_D_Loss:0.0015 ||Epoch_G_Loss:0.8568
timer:  0.7297 sec.
-------------
Epoch 64/200
-------------
(train)
-------------
epoch 64 || Epoch_D_Loss:0.0375 ||Epoch_G_Loss:0.8728
timer:  0.7267 sec.
-------------
Epoch 65/200
-------------
(train)
-------------
epoch 65 || Epoch_D_Loss:0.0063 ||Epoch_G_Loss:0.6889
timer:  0.7381 sec.
-------------
Epoch 66/200
-------------
(train)
-------------
epoch 66 || Epoch_D_Loss:0.0038 ||Epoch_G_Loss:0.8209
timer:  0.7297 sec.
-------------
Epoch 67/200
-------------
(train)
-------------
epoch 67 || Epoch_D_Loss:0.0022 ||Epoch_G_Loss:0.8709
timer:  0.7559 sec.
-------------
Epoch 68/200
-------------
(train)
-------------
epoch 68 || Epoch_D_Loss:0.0011 ||Epoch_G_Loss:0.8871
timer:  0.7298 sec.
-------------
Epoch 69/200
-------------
(train)
-------------
epoch 69 || Epoch_D_Loss:0.0414 ||Epoch_G_Loss:0.9295
timer:  0.7275 sec.
-------------
Epoch 70/200
-------------
(train)
-------------
epoch 70 || Epoch_D_Loss:0.0088 ||Epoch_G_Loss:0.7318
timer:  0.7226 sec.
-------------
Epoch 71/200
-------------
(train)
-------------
epoch 71 || Epoch_D_Loss:0.0017 ||Epoch_G_Loss:0.8082
timer:  0.7209 sec.
-------------
Epoch 72/200
-------------
(train)
-------------
epoch 72 || Epoch_D_Loss:0.0013 ||Epoch_G_Loss:0.8387
timer:  0.7196 sec.
-------------
Epoch 73/200
-------------
(train)
-------------
epoch 73 || Epoch_D_Loss:0.0013 ||Epoch_G_Loss:0.9041
timer:  0.7261 sec.
-------------
Epoch 74/200
-------------
(train)
-------------
epoch 74 || Epoch_D_Loss:0.0522 ||Epoch_G_Loss:0.9280
timer:  0.7300 sec.
-------------
Epoch 75/200
-------------
(train)
-------------
epoch 75 || Epoch_D_Loss:0.0056 ||Epoch_G_Loss:0.6952
timer:  0.7258 sec.
-------------
Epoch 76/200
-------------
(train)
-------------
epoch 76 || Epoch_D_Loss:0.0023 ||Epoch_G_Loss:0.8027
timer:  0.7219 sec.
-------------
Epoch 77/200
-------------
(train)
-------------
epoch 77 || Epoch_D_Loss:0.0025 ||Epoch_G_Loss:0.8502
timer:  0.7210 sec.
-------------
Epoch 78/200
-------------
(train)
-------------
epoch 78 || Epoch_D_Loss:0.0008 ||Epoch_G_Loss:0.8654
timer:  0.7208 sec.
-------------
Epoch 79/200
-------------
(train)
-------------
epoch 79 || Epoch_D_Loss:0.0008 ||Epoch_G_Loss:0.9063
timer:  0.7214 sec.
-------------
Epoch 80/200
-------------
(train)
-------------
epoch 80 || Epoch_D_Loss:0.0458 ||Epoch_G_Loss:0.9730
timer:  0.7253 sec.
-------------
Epoch 81/200
-------------
(train)
-------------
epoch 81 || Epoch_D_Loss:0.0023 ||Epoch_G_Loss:0.7860
timer:  0.7200 sec.
-------------
Epoch 82/200
-------------
(train)
-------------
epoch 82 || Epoch_D_Loss:0.0012 ||Epoch_G_Loss:0.8159
timer:  0.7201 sec.
-------------
Epoch 83/200
-------------
(train)
-------------
epoch 83 || Epoch_D_Loss:0.0011 ||Epoch_G_Loss:0.8737
timer:  0.7207 sec.
-------------
Epoch 84/200
-------------
(train)
-------------
epoch 84 || Epoch_D_Loss:0.0444 ||Epoch_G_Loss:0.8085
timer:  0.7164 sec.
-------------
Epoch 85/200
-------------
(train)
-------------
epoch 85 || Epoch_D_Loss:0.0100 ||Epoch_G_Loss:0.7245
timer:  0.7192 sec.
-------------
Epoch 86/200
-------------
(train)
-------------
epoch 86 || Epoch_D_Loss:0.0019 ||Epoch_G_Loss:0.7648
timer:  0.7202 sec.
-------------
Epoch 87/200
-------------
(train)
-------------
epoch 87 || Epoch_D_Loss:0.0017 ||Epoch_G_Loss:0.8417
timer:  0.7172 sec.
-------------
Epoch 88/200
-------------
(train)
-------------
epoch 88 || Epoch_D_Loss:0.0009 ||Epoch_G_Loss:0.8620
timer:  0.7171 sec.
-------------
Epoch 89/200
-------------
(train)
-------------
epoch 89 || Epoch_D_Loss:0.0011 ||Epoch_G_Loss:0.9353
timer:  0.7189 sec.
-------------
Epoch 90/200
-------------
(train)
-------------
epoch 90 || Epoch_D_Loss:0.0538 ||Epoch_G_Loss:0.9575
timer:  0.7199 sec.
-------------
Epoch 91/200
-------------
(train)
-------------
epoch 91 || Epoch_D_Loss:0.0036 ||Epoch_G_Loss:0.7752
timer:  0.7231 sec.
-------------
Epoch 92/200
-------------
(train)
-------------
epoch 92 || Epoch_D_Loss:0.0013 ||Epoch_G_Loss:0.8001
timer:  0.7212 sec.
-------------
Epoch 93/200
-------------
(train)
-------------
epoch 93 || Epoch_D_Loss:0.0029 ||Epoch_G_Loss:0.9208
timer:  0.7198 sec.
-------------
Epoch 94/200
-------------
(train)
-------------
epoch 94 || Epoch_D_Loss:0.0009 ||Epoch_G_Loss:0.9002
timer:  0.7233 sec.
-------------
Epoch 95/200
-------------
(train)
-------------
epoch 95 || Epoch_D_Loss:0.0020 ||Epoch_G_Loss:0.8902
timer:  0.7227 sec.
-------------
Epoch 96/200
-------------
(train)
-------------
epoch 96 || Epoch_D_Loss:0.0467 ||Epoch_G_Loss:0.8899
timer:  0.7380 sec.
-------------
Epoch 97/200
-------------
(train)
-------------
epoch 97 || Epoch_D_Loss:0.0025 ||Epoch_G_Loss:0.7825
timer:  0.7333 sec.
-------------
Epoch 98/200
-------------
(train)
-------------
epoch 98 || Epoch_D_Loss:0.0037 ||Epoch_G_Loss:0.8136
timer:  0.7191 sec.
-------------
Epoch 99/200
-------------
(train)
-------------
epoch 99 || Epoch_D_Loss:0.0096 ||Epoch_G_Loss:0.9419
timer:  0.7208 sec.
-------------
Epoch 100/200
-------------
(train)
-------------
epoch 100 || Epoch_D_Loss:0.0014 ||Epoch_G_Loss:0.8698
timer:  0.7468 sec.
-------------
Epoch 101/200
-------------
(train)
-------------
epoch 101 || Epoch_D_Loss:0.0008 ||Epoch_G_Loss:0.9751
timer:  0.7229 sec.
-------------
Epoch 102/200
-------------
(train)
-------------
epoch 102 || Epoch_D_Loss:0.0005 ||Epoch_G_Loss:0.9452
timer:  0.7198 sec.
-------------
Epoch 103/200
-------------
(train)
-------------
epoch 103 || Epoch_D_Loss:0.0007 ||Epoch_G_Loss:0.9833
timer:  0.7279 sec.
-------------
Epoch 104/200
-------------
(train)
-------------
epoch 104 || Epoch_D_Loss:0.1555 ||Epoch_G_Loss:1.0839
timer:  0.7222 sec.
-------------
Epoch 105/200
-------------
(train)
-------------
epoch 105 || Epoch_D_Loss:0.0103 ||Epoch_G_Loss:0.6298
timer:  0.7233 sec.
-------------
Epoch 106/200
-------------
(train)
-------------
epoch 106 || Epoch_D_Loss:0.0061 ||Epoch_G_Loss:0.7351
timer:  0.7223 sec.
-------------
Epoch 107/200
-------------
(train)
-------------
epoch 107 || Epoch_D_Loss:0.0036 ||Epoch_G_Loss:0.7819
timer:  0.7340 sec.
-------------
Epoch 108/200
-------------
(train)
-------------
epoch 108 || Epoch_D_Loss:0.0028 ||Epoch_G_Loss:0.8024
timer:  0.7279 sec.
-------------
Epoch 109/200
-------------
(train)
-------------
epoch 109 || Epoch_D_Loss:0.0028 ||Epoch_G_Loss:0.9204
timer:  0.7284 sec.
-------------
Epoch 110/200
-------------
(train)
-------------
epoch 110 || Epoch_D_Loss:0.0069 ||Epoch_G_Loss:1.1190
timer:  0.7254 sec.
-------------
Epoch 111/200
-------------
(train)
-------------
epoch 111 || Epoch_D_Loss:0.0006 ||Epoch_G_Loss:1.0324
timer:  0.7267 sec.
-------------
Epoch 112/200
-------------
(train)
-------------
epoch 112 || Epoch_D_Loss:0.0014 ||Epoch_G_Loss:0.9086
timer:  0.7268 sec.
-------------
Epoch 113/200
-------------
(train)
-------------
epoch 113 || Epoch_D_Loss:0.0014 ||Epoch_G_Loss:0.9236
timer:  0.7270 sec.
-------------
Epoch 114/200
-------------
(train)
-------------
epoch 114 || Epoch_D_Loss:0.0561 ||Epoch_G_Loss:0.9581
timer:  0.7281 sec.
-------------
Epoch 115/200
-------------
(train)
-------------
epoch 115 || Epoch_D_Loss:0.0025 ||Epoch_G_Loss:0.7752
timer:  0.7249 sec.
-------------
Epoch 116/200
-------------
(train)
-------------
epoch 116 || Epoch_D_Loss:0.0021 ||Epoch_G_Loss:0.8565
timer:  0.7257 sec.
-------------
Epoch 117/200
-------------
(train)
-------------
epoch 117 || Epoch_D_Loss:0.0317 ||Epoch_G_Loss:0.8358
timer:  0.7263 sec.
-------------
Epoch 118/200
-------------
(train)
-------------
epoch 118 || Epoch_D_Loss:0.0104 ||Epoch_G_Loss:0.7355
timer:  0.7370 sec.
-------------
Epoch 119/200
-------------
(train)
-------------
epoch 119 || Epoch_D_Loss:0.0024 ||Epoch_G_Loss:0.8858
timer:  0.7332 sec.
-------------
Epoch 120/200
-------------
(train)
-------------
epoch 120 || Epoch_D_Loss:0.0337 ||Epoch_G_Loss:0.7324
timer:  0.7300 sec.
-------------
Epoch 121/200
-------------
(train)
-------------
epoch 121 || Epoch_D_Loss:0.0020 ||Epoch_G_Loss:0.7945
timer:  0.7221 sec.
-------------
Epoch 122/200
-------------
(train)
-------------
epoch 122 || Epoch_D_Loss:0.0010 ||Epoch_G_Loss:0.8590
timer:  0.7202 sec.
-------------
Epoch 123/200
-------------
(train)
-------------
epoch 123 || Epoch_D_Loss:0.0009 ||Epoch_G_Loss:0.8890
timer:  0.7228 sec.
-------------
Epoch 124/200
-------------
(train)
-------------
epoch 124 || Epoch_D_Loss:0.0006 ||Epoch_G_Loss:0.8837
timer:  0.7254 sec.
-------------
Epoch 125/200
-------------
(train)
-------------
epoch 125 || Epoch_D_Loss:0.0068 ||Epoch_G_Loss:0.9388
timer:  0.7226 sec.
-------------
Epoch 126/200
-------------
(train)
-------------
epoch 126 || Epoch_D_Loss:0.0567 ||Epoch_G_Loss:0.6943
timer:  0.7223 sec.
-------------
Epoch 127/200
-------------
(train)
-------------
epoch 127 || Epoch_D_Loss:0.0023 ||Epoch_G_Loss:0.7448
timer:  0.7190 sec.
-------------
Epoch 128/200
-------------
(train)
-------------
epoch 128 || Epoch_D_Loss:0.0019 ||Epoch_G_Loss:0.8421
timer:  0.7241 sec.
-------------
Epoch 129/200
-------------
(train)
-------------
epoch 129 || Epoch_D_Loss:0.0044 ||Epoch_G_Loss:0.9485
timer:  0.7198 sec.
-------------
Epoch 130/200
-------------
(train)
-------------
epoch 130 || Epoch_D_Loss:0.0442 ||Epoch_G_Loss:1.0138
timer:  0.7290 sec.
-------------
Epoch 131/200
-------------
(train)
-------------
epoch 131 || Epoch_D_Loss:0.0076 ||Epoch_G_Loss:0.7135
timer:  0.7240 sec.
-------------
Epoch 132/200
-------------
(train)
-------------
epoch 132 || Epoch_D_Loss:0.0017 ||Epoch_G_Loss:0.7633
timer:  0.7216 sec.
-------------
Epoch 133/200
-------------
(train)
-------------
epoch 133 || Epoch_D_Loss:0.0015 ||Epoch_G_Loss:0.8278
timer:  0.7209 sec.
-------------
Epoch 134/200
-------------
(train)
-------------
epoch 134 || Epoch_D_Loss:0.0020 ||Epoch_G_Loss:0.9835
timer:  0.7225 sec.
-------------
Epoch 135/200
-------------
(train)
-------------
epoch 135 || Epoch_D_Loss:0.0004 ||Epoch_G_Loss:0.9521
timer:  0.7191 sec.
-------------
Epoch 136/200
-------------
(train)
-------------
epoch 136 || Epoch_D_Loss:0.0004 ||Epoch_G_Loss:1.0310
timer:  0.7201 sec.
-------------
Epoch 137/200
-------------
(train)
-------------
epoch 137 || Epoch_D_Loss:0.0633 ||Epoch_G_Loss:1.0482
timer:  0.7257 sec.
-------------
Epoch 138/200
-------------
(train)
-------------
epoch 138 || Epoch_D_Loss:0.0215 ||Epoch_G_Loss:0.9015
timer:  0.7233 sec.
-------------
Epoch 139/200
-------------
(train)
-------------
epoch 139 || Epoch_D_Loss:0.0041 ||Epoch_G_Loss:0.8207
timer:  0.7242 sec.
-------------
Epoch 140/200
-------------
(train)
-------------
epoch 140 || Epoch_D_Loss:0.0016 ||Epoch_G_Loss:0.8500
timer:  0.7291 sec.
-------------
Epoch 141/200
-------------
(train)
-------------
epoch 141 || Epoch_D_Loss:0.0023 ||Epoch_G_Loss:0.8946
timer:  0.7330 sec.
-------------
Epoch 142/200
-------------
(train)
-------------
epoch 142 || Epoch_D_Loss:0.0011 ||Epoch_G_Loss:0.8823
timer:  0.7250 sec.
-------------
Epoch 143/200
-------------
(train)
-------------
epoch 143 || Epoch_D_Loss:0.0024 ||Epoch_G_Loss:1.0055
timer:  0.7228 sec.
-------------
Epoch 144/200
-------------
(train)
-------------
epoch 144 || Epoch_D_Loss:0.0616 ||Epoch_G_Loss:0.9888
timer:  0.7235 sec.
-------------
Epoch 145/200
-------------
(train)
-------------
epoch 145 || Epoch_D_Loss:0.0026 ||Epoch_G_Loss:0.8180
timer:  0.7214 sec.
-------------
Epoch 146/200
-------------
(train)
-------------
epoch 146 || Epoch_D_Loss:0.0016 ||Epoch_G_Loss:0.8650
timer:  0.7242 sec.
-------------
Epoch 147/200
-------------
(train)
-------------
epoch 147 || Epoch_D_Loss:0.0009 ||Epoch_G_Loss:0.8336
timer:  0.7255 sec.
-------------
Epoch 148/200
-------------
(train)
-------------
epoch 148 || Epoch_D_Loss:0.0011 ||Epoch_G_Loss:0.9114
timer:  0.7221 sec.
-------------
Epoch 149/200
-------------
(train)
-------------
epoch 149 || Epoch_D_Loss:0.0314 ||Epoch_G_Loss:0.9916
timer:  0.7217 sec.
-------------
Epoch 150/200
-------------
(train)
-------------
epoch 150 || Epoch_D_Loss:0.0159 ||Epoch_G_Loss:0.7072
timer:  0.7261 sec.
-------------
Epoch 151/200
-------------
(train)
-------------
epoch 151 || Epoch_D_Loss:0.0018 ||Epoch_G_Loss:0.8146
timer:  0.7238 sec.
-------------
Epoch 152/200
-------------
(train)
-------------
epoch 152 || Epoch_D_Loss:0.0016 ||Epoch_G_Loss:0.8835
timer:  0.7259 sec.
-------------
Epoch 153/200
-------------
(train)
-------------
epoch 153 || Epoch_D_Loss:0.0078 ||Epoch_G_Loss:1.0363
timer:  0.7235 sec.
-------------
Epoch 154/200
-------------
(train)
-------------
epoch 154 || Epoch_D_Loss:0.0333 ||Epoch_G_Loss:0.8053
timer:  0.7234 sec.
-------------
Epoch 155/200
-------------
(train)
-------------
epoch 155 || Epoch_D_Loss:0.0020 ||Epoch_G_Loss:0.8146
timer:  0.7232 sec.
-------------
Epoch 156/200
-------------
(train)
-------------
epoch 156 || Epoch_D_Loss:0.0024 ||Epoch_G_Loss:0.8763
timer:  0.7245 sec.
-------------
Epoch 157/200
-------------
(train)
-------------
epoch 157 || Epoch_D_Loss:0.0037 ||Epoch_G_Loss:0.8991
timer:  0.7251 sec.
-------------
Epoch 158/200
-------------
(train)
-------------
epoch 158 || Epoch_D_Loss:0.0352 ||Epoch_G_Loss:0.9261
timer:  0.7250 sec.
-------------
Epoch 159/200
-------------
(train)
-------------
epoch 159 || Epoch_D_Loss:0.0104 ||Epoch_G_Loss:0.7463
timer:  0.7217 sec.
-------------
Epoch 160/200
-------------
(train)
-------------
epoch 160 || Epoch_D_Loss:0.0028 ||Epoch_G_Loss:0.8617
timer:  0.7248 sec.
-------------
Epoch 161/200
-------------
(train)
-------------
epoch 161 || Epoch_D_Loss:0.0021 ||Epoch_G_Loss:0.9127
timer:  0.7300 sec.
-------------
Epoch 162/200
-------------
(train)
-------------
epoch 162 || Epoch_D_Loss:0.0187 ||Epoch_G_Loss:0.8745
timer:  0.7322 sec.
-------------
Epoch 163/200
-------------
(train)
-------------
epoch 163 || Epoch_D_Loss:0.0025 ||Epoch_G_Loss:0.8871
timer:  0.7360 sec.
-------------
Epoch 164/200
-------------
(train)
-------------
epoch 164 || Epoch_D_Loss:0.0008 ||Epoch_G_Loss:0.8840
timer:  0.7259 sec.
-------------
Epoch 165/200
-------------
(train)
-------------
epoch 165 || Epoch_D_Loss:0.0290 ||Epoch_G_Loss:0.9592
timer:  0.7324 sec.
-------------
Epoch 166/200
-------------
(train)
-------------
epoch 166 || Epoch_D_Loss:0.0095 ||Epoch_G_Loss:0.8147
timer:  0.7241 sec.
-------------
Epoch 167/200
-------------
(train)
-------------
epoch 167 || Epoch_D_Loss:0.0017 ||Epoch_G_Loss:0.8852
timer:  0.7227 sec.
-------------
Epoch 168/200
-------------
(train)
-------------
epoch 168 || Epoch_D_Loss:0.0124 ||Epoch_G_Loss:0.8975
timer:  0.7256 sec.
-------------
Epoch 169/200
-------------
(train)
-------------
epoch 169 || Epoch_D_Loss:0.0127 ||Epoch_G_Loss:0.8617
timer:  0.7270 sec.
-------------
Epoch 170/200
-------------
(train)
-------------
epoch 170 || Epoch_D_Loss:0.0043 ||Epoch_G_Loss:0.8565
timer:  0.7238 sec.
-------------
Epoch 171/200
-------------
(train)
-------------
epoch 171 || Epoch_D_Loss:0.0012 ||Epoch_G_Loss:0.9055
timer:  0.7263 sec.
-------------
Epoch 172/200
-------------
(train)
-------------
epoch 172 || Epoch_D_Loss:0.0300 ||Epoch_G_Loss:0.9339
timer:  0.7229 sec.
-------------
Epoch 173/200
-------------
(train)
-------------
epoch 173 || Epoch_D_Loss:0.0323 ||Epoch_G_Loss:0.7781
timer:  0.7257 sec.
-------------
Epoch 174/200
-------------
(train)
-------------
epoch 174 || Epoch_D_Loss:0.0057 ||Epoch_G_Loss:0.7429
timer:  0.7237 sec.
-------------
Epoch 175/200
-------------
(train)
-------------
epoch 175 || Epoch_D_Loss:0.0027 ||Epoch_G_Loss:0.8056
timer:  0.7228 sec.
-------------
Epoch 176/200
-------------
(train)
-------------
epoch 176 || Epoch_D_Loss:0.0013 ||Epoch_G_Loss:0.7961
timer:  0.7236 sec.
-------------
Epoch 177/200
-------------
(train)
-------------
epoch 177 || Epoch_D_Loss:0.0009 ||Epoch_G_Loss:0.8577
timer:  0.7254 sec.
-------------
Epoch 178/200
-------------
(train)
-------------
epoch 178 || Epoch_D_Loss:0.0016 ||Epoch_G_Loss:1.0004
timer:  0.7239 sec.
-------------
Epoch 179/200
-------------
(train)
-------------
epoch 179 || Epoch_D_Loss:0.0479 ||Epoch_G_Loss:0.8469
timer:  0.7232 sec.
-------------
Epoch 180/200
-------------
(train)
-------------
epoch 180 || Epoch_D_Loss:0.0031 ||Epoch_G_Loss:0.6928
timer:  0.7236 sec.
-------------
Epoch 181/200
-------------
(train)
-------------
epoch 181 || Epoch_D_Loss:0.0010 ||Epoch_G_Loss:0.8195
timer:  0.7271 sec.
-------------
Epoch 182/200
-------------
(train)
-------------
epoch 182 || Epoch_D_Loss:0.0008 ||Epoch_G_Loss:0.8560
timer:  0.7243 sec.
-------------
Epoch 183/200
-------------
(train)
-------------
epoch 183 || Epoch_D_Loss:0.0191 ||Epoch_G_Loss:1.0310
timer:  0.7217 sec.
-------------
Epoch 184/200
-------------
(train)
-------------
epoch 184 || Epoch_D_Loss:0.0085 ||Epoch_G_Loss:0.7468
timer:  0.7303 sec.
-------------
Epoch 185/200
-------------
(train)
-------------
epoch 185 || Epoch_D_Loss:0.0032 ||Epoch_G_Loss:0.9024
timer:  0.7321 sec.
-------------
Epoch 186/200
-------------
(train)
-------------
epoch 186 || Epoch_D_Loss:0.0016 ||Epoch_G_Loss:0.8672
timer:  0.7283 sec.
-------------
Epoch 187/200
-------------
(train)
-------------
epoch 187 || Epoch_D_Loss:0.0476 ||Epoch_G_Loss:0.9672
timer:  0.7208 sec.
-------------
Epoch 188/200
-------------
(train)
-------------
epoch 188 || Epoch_D_Loss:0.0077 ||Epoch_G_Loss:0.7749
timer:  0.7255 sec.
-------------
Epoch 189/200
-------------
(train)
-------------
epoch 189 || Epoch_D_Loss:0.0045 ||Epoch_G_Loss:0.8037
timer:  0.7221 sec.
-------------
Epoch 190/200
-------------
(train)
-------------
epoch 190 || Epoch_D_Loss:0.0031 ||Epoch_G_Loss:0.8678
timer:  0.7244 sec.
-------------
Epoch 191/200
-------------
(train)
-------------
epoch 191 || Epoch_D_Loss:0.0010 ||Epoch_G_Loss:0.9078
timer:  0.7223 sec.
-------------
Epoch 192/200
-------------
(train)
-------------
epoch 192 || Epoch_D_Loss:0.0018 ||Epoch_G_Loss:1.0057
timer:  0.7271 sec.
-------------
Epoch 193/200
-------------
(train)
-------------
epoch 193 || Epoch_D_Loss:0.0322 ||Epoch_G_Loss:0.8226
timer:  0.7226 sec.
-------------
Epoch 194/200
-------------
(train)
-------------
epoch 194 || Epoch_D_Loss:0.0012 ||Epoch_G_Loss:0.8305
timer:  0.7231 sec.
-------------
Epoch 195/200
-------------
(train)
-------------
epoch 195 || Epoch_D_Loss:0.0020 ||Epoch_G_Loss:0.9072
timer:  0.7225 sec.
-------------
Epoch 196/200
-------------
(train)
-------------
epoch 196 || Epoch_D_Loss:0.0049 ||Epoch_G_Loss:1.0098
timer:  0.7306 sec.
-------------
Epoch 197/200
-------------
(train)
-------------
epoch 197 || Epoch_D_Loss:0.0216 ||Epoch_G_Loss:0.9132
timer:  0.7397 sec.
-------------
Epoch 198/200
-------------
(train)
-------------
epoch 198 || Epoch_D_Loss:0.0172 ||Epoch_G_Loss:0.8279
timer:  0.7386 sec.
-------------
Epoch 199/200
-------------
(train)
-------------
epoch 199 || Epoch_D_Loss:0.0021 ||Epoch_G_Loss:0.8379
timer:  0.7345 sec.</code></pre>
</div>
</div>
</section>
<section id="이미지-생성-결과" class="level3">
<h3 class="anchored" data-anchor-id="이미지-생성-결과">이미지 생성 결과</h3>
<div class="cell" data-outputid="a751b80b-e0bb-4441-c1ab-e555322300b5">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">"cuda:0"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>)</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 입력 난수</span></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">8</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>z_dim <span class="op">=</span> <span class="dv">20</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>fixed_z <span class="op">=</span> torch.randn(batch_size, z_dim)</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>fixed_z <span class="op">=</span> fixed_z.view(fixed_z.size(<span class="dv">0</span>), fixed_z.size(<span class="dv">1</span>), <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 화상 생성</span></span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>G_update.<span class="bu">eval</span>()</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>fake_images <span class="op">=</span> G_update(fixed_z.to(device))</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a><span class="co"># 훈련 데이터</span></span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a>batch_iterator <span class="op">=</span> <span class="bu">iter</span>(train_dataloader)  <span class="co"># 반복자로 변환</span></span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a>imges <span class="op">=</span> <span class="bu">next</span>(batch_iterator)  <span class="co"># 1번째 요소를 꺼낸다</span></span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a><span class="co"># 출력</span></span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">6</span>))</span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="dv">5</span>):</span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 상단에 훈련 데이터를,</span></span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">2</span>, <span class="dv">5</span>, i<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a>    plt.imshow(imges[i][<span class="dv">0</span>].cpu().detach().numpy(), <span class="st">'gray'</span>)</span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 하단에 생성 데이터를 표시한다</span></span>
<span id="cb33-26"><a href="#cb33-26" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">5</span><span class="op">+</span>i<span class="op">+</span><span class="dv">1</span>)</span>
<span id="cb33-27"><a href="#cb33-27" aria-hidden="true" tabindex="-1"></a>    plt.imshow(fake_images[i][<span class="dv">0</span>].cpu().detach().numpy(), <span class="st">'gray'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="DCGAN_files/figure-html/cell-26-output-1.png" class="img-fluid"></p>
</div>
</div>


</section>
</section>
</section>

</main> <!-- /main -->

<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>